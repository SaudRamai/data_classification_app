"""
Data Governance Application
"""
import sys
import os
import pathlib

# Add the project root to the Python path
_here = pathlib.Path(str(__file__)).resolve()
_dir = _here.parent
# Traverse up to find directory containing 'src'
for _ in range(3):
    if (_dir / "src").exists():
        if str(_dir) not in sys.path:
            sys.path.insert(0, str(_dir))
        break
    _dir = _dir.parent

import streamlit as st

# Page configuration - MUST be the first Streamlit command
st.set_page_config(
    page_title="Monitoring & Compliance - Data Governance App",
    page_icon="âœ…",
    layout="wide"
)

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Tuple
from src.ui.theme import apply_global_theme
from io import StringIO
from src.connectors.snowflake_connector import snowflake_connector
from src.config.settings import settings
from src.services.authorization_service import authz
import logging
from src.services.asset_utils import get_health_score_metrics
from src.ui.quick_links import render_quick_links
from src.components.filters import render_global_filters

logger = logging.getLogger(__name__)

# Apply centralized theme
apply_global_theme()

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def _resolve_db() -> Optional[str]:
    """Resolve active database safely. Defaults to DATA_CLASSIFICATION_DB."""
    try:
        db = st.session_state.get('sf_database')
        if db:
            return db
    except Exception:
        pass
    
    # Try settings
    try:
        db = settings.SNOWFLAKE_DATABASE
        if db:
            return db
    except Exception:
        pass
    
    # Try current database
    try:
        row = snowflake_connector.execute_query("SELECT CURRENT_DATABASE() AS DB") or []
        db = row[0].get('DB') if row else None
        if db:
            return db
    except Exception:
        pass
    
    # Default to DATA_CLASSIFICATION_DB
    return "DATA_CLASSIFICATION_DB"

def _gv_schema() -> str:
    """Return the governance schema to use for queries. Defaults to DATA_CLASSIFICATION_GOVERNANCE."""
    try:
        gs = st.session_state.get("governance_schema")
        if gs and str(gs).strip():
            return str(gs).strip()
    except Exception:
        pass
    return "DATA_CLASSIFICATION_GOVERNANCE"

def _table_exists(db: Optional[str], schema: str, table: str) -> bool:
    """Check if a table exists."""
    if not db:
        return False
    try:
        rows = snowflake_connector.execute_query(
            """
            SELECT 1 AS X
            FROM INFORMATION_SCHEMA.TABLES
            WHERE TABLE_CATALOG = %(db)s AND TABLE_SCHEMA = %(s)s AND TABLE_NAME = %(t)s
            LIMIT 1
            """,
            {"db": db, "s": schema, "t": table},
        ) or []
        return bool(rows)
    except Exception:
        return False

# ============================================================================
# FILTER HELPER FUNCTIONS
# ============================================================================

@st.cache_data(ttl=300)
def _list_warehouses() -> List[str]:
    """Best-effort list of accessible warehouses for selection."""
    try:
        rows = snowflake_connector.execute_query("SHOW WAREHOUSES") or []
        return [r.get("name") or r.get("NAME") for r in rows if (r.get("name") or r.get("NAME"))]
    except Exception:
        return []

def _apply_warehouse(wh: Optional[str]) -> None:
    """Resume and USE the selected warehouse; ignore errors silently."""
    if not wh:
        return
    try:
        try:
            snowflake_connector.execute_non_query(f"ALTER WAREHOUSE {wh} RESUME")
        except Exception:
            pass
        try:
            snowflake_connector.execute_non_query(f"USE WAREHOUSE {wh}")
        except Exception:
            pass
        st.session_state['sf_warehouse'] = wh
    except Exception:
        pass

@st.cache_data(ttl=300)
def _list_databases() -> List[str]:
    """Best-effort list of accessible databases."""
    try:
        rows = snowflake_connector.execute_query("SHOW DATABASES") or []
        return [r.get("name") or r.get("NAME") for r in rows if (r.get("name") or r.get("NAME"))]
    except Exception:
        return []

def _apply_database(db: Optional[str]) -> None:
    """USE the selected database and persist it; ignore errors silently."""
    try:
        if db and db != "All":
            try:
                snowflake_connector.execute_non_query(f"USE DATABASE {db}")
            except Exception:
                pass
            st.session_state['sf_database'] = db
        else:
            # Clear explicit selection; downstream will resolve or prompt
            st.session_state.pop('sf_database', None)
    except Exception:
        pass

@st.cache_data(ttl=300)
def _list_schemas(db: Optional[str]) -> List[str]:
    """List schemas in the given database."""
    if not db or db == "All":
        return []
    try:
        rows = snowflake_connector.execute_query(
            f"""
            SELECT SCHEMA_NAME
            FROM INFORMATION_SCHEMA.SCHEMATA
            ORDER BY SCHEMA_NAME
            """
        ) or []
        return [r.get('SCHEMA_NAME') for r in rows if r.get('SCHEMA_NAME')]
    except Exception:
        return []

@st.cache_data(ttl=300)
def _list_objects(db: Optional[str], schema: Optional[str]) -> List[str]:
    """List tables and views in the given database/schema."""
    if not db or db == "All" or not schema or schema == "All":
        return []
    try:
        rows = snowflake_connector.execute_query(
            f"""
            SELECT TABLE_NAME AS NAME, 'TABLE' AS TYPE
            FROM INFORMATION_SCHEMA.TABLES
            WHERE TABLE_SCHEMA = %(s)s
            UNION ALL
            SELECT TABLE_NAME AS NAME, 'VIEW' AS TYPE
            FROM INFORMATION_SCHEMA.VIEWS
            WHERE TABLE_SCHEMA = %(s)s
            ORDER BY NAME
            """,
            {"s": schema},
        ) or []
        return [r.get('NAME') for r in rows if r.get('NAME')]
    except Exception:
        return []

@st.cache_data(ttl=300)
def _list_columns(db: Optional[str], schema: Optional[str], obj: Optional[str]) -> List[str]:
    """List columns in the given table/view."""
    if not db or db == "All" or not schema or schema == "All" or not obj or obj == "All":
        return []
    try:
        rows = snowflake_connector.execute_query(
            f"""
            SELECT COLUMN_NAME
            FROM INFORMATION_SCHEMA.COLUMNS
            WHERE TABLE_SCHEMA = %(s)s AND TABLE_NAME = %(t)s
            ORDER BY ORDINAL_POSITION
            """,
            {"s": schema, "t": obj},
        ) or []
        return [r.get('COLUMN_NAME') for r in rows if r.get('COLUMN_NAME')]
    except Exception:
        return []

def _build_filters(filters: Dict, db_val: str, db_col='table_catalog', schema_col='table_schema', table_col='table_name') -> Tuple[str, Dict]:
    """Build SQL WHERE clauses and params for filters."""
    clauses = []
    params = {}
    
    if db_val and db_val != "All":
        clauses.append(f"{db_col} = %(db_val)s")
        params['db_val'] = db_val
        
    if filters and filters.get('schema'):
        clauses.append(f"{schema_col} = %(schema_val)s")
        params['schema_val'] = filters['schema']
        
    if filters and filters.get('table'):
        clauses.append(f"{table_col} = %(table_val)s")
        params['table_val'] = filters['table']
        
    return (" AND ".join(clauses) if clauses else "1=1", params)

# ============================================================================
# DATA FETCHING FUNCTIONS  
# ============================================================================

# REMOVED CACHE to force fresh data - enable cache after debugging
def get_compliance_overview_metrics(db: str, filters: dict = None) -> Dict:
    """Fetch key compliance metrics using the health program logic (from Dashboard)."""
    schema = _gv_schema()
    
    metrics = {
        'classification_coverage': 0.0,
        'five_day_compliance': 0.0,
        'annual_review_rate': 0.0,
        'policy_violations': 0,
        'coverage_trend': 0.0,
        'compliance_trend': 0.0,
        'overall_status': 'ðŸ”´ Unknown',
        'snowflake_tag_compliance': 0.0
    }
    
    try:
        # Use the authoritative health score metrics from asset_utils (same as Dashboard)
        health = get_health_score_metrics(db, schema)
        
        if health:
            metrics['classification_coverage'] = health.get('coverage_pct', 0.0)
            metrics['five_day_compliance'] = health.get('sla_pct', 0.0)
            metrics['annual_review_rate'] = health.get('reviews_pct', 0.0)
            metrics['overall_status'] = health.get('health_status', 'ðŸ”´ Unknown')
            
            # Policy violations is the count of unclassified assets
            total_assets = health.get('total_assets', 0)
            classified_count = int(total_assets * (metrics['classification_coverage'] / 100.0))
            metrics['policy_violations'] = max(0, total_assets - classified_count)
            
            # Snowflake Tag Compliance (using governance_pct as proxy if not explicit)
            metrics['snowflake_tag_compliance'] = health.get('governance_pct', 0.0)
            
            # Trends - check if we can get trend data from the database
            try:
                # Basic trend logic: compare current to last month or use static for now
                metrics['coverage_trend'] = 2.1 # Placeholder until historical data is available
                metrics['compliance_trend'] = -0.5
            except Exception:
                pass
                
    except Exception as e:
        logger.error(f"Error in get_compliance_overview_metrics: {e}")
            
    return metrics
    
# REMOVED CACHE to force fresh data - enable cache after debugging
def get_classification_requirements_metrics(db: str) -> Dict:
    """Fetch detailed classification requirements metrics using INFORMATION_SCHEMA.
    
    This comprehensive query calculates:
    - 5-Day Rule Compliance
    - Annual Review Completion
    - Documentation Completeness
    - Classification Coverage
    - Policy Violations
    - Overall Compliance Status
    
    Args:
        db: The database to query
        
    Returns:
        Dictionary with all classification requirements metrics
    """
    try:
        query = f"""
        WITH metrics AS (
            -- 5-Day Rule
            SELECT 
                ROUND(
                    COUNT_IF(comment IS NOT NULL AND DATEDIFF('day', created, CURRENT_DATE) <= 5) * 100.0
                    / COUNT(*),
                    1
                ) AS five_day_compliance,
                -- Annual Review
                ROUND(
                    COUNT_IF(YEAR(last_altered) = YEAR(CURRENT_DATE)) * 100.0
                    / COUNT(*),
                    1
                ) AS annual_review,
                -- Documentation Completeness
                (SELECT ROUND(
                        COUNT_IF(table_comment IS NOT NULL AND total_columns = commented_columns) * 100.0
                        / COUNT(*),1)
                 FROM (
                     SELECT t.table_catalog, t.table_schema, t.table_name,
                            t.comment AS table_comment,
                            c.total_columns, c.commented_columns
                     FROM INFORMATION_SCHEMA.TABLES t
                     JOIN (
                         SELECT table_catalog, table_schema, table_name,
                                COUNT(*) AS total_columns,
                                COUNT_IF(comment IS NOT NULL) AS commented_columns
                         FROM INFORMATION_SCHEMA.COLUMNS
                         GROUP BY table_catalog, table_schema, table_name
                     ) c USING (table_catalog, table_schema, table_name)
                 ) sub
                ) AS doc_completeness,
                -- Classification Coverage
                ROUND(
                    COUNT_IF(comment IS NOT NULL) * 100.0 / COUNT(*),
                    1
                ) AS coverage,
                -- Policy Violations
                (SELECT COUNT(*) 
                 FROM INFORMATION_SCHEMA.TABLES
                 WHERE comment IS NULL) AS policy_violations
            FROM INFORMATION_SCHEMA.TABLES
        )
        SELECT *,
               CASE
                   WHEN five_day_compliance >= 95
                        AND annual_review = 100
                        AND doc_completeness >= 95
                        AND coverage >= 95
                        AND policy_violations = 0
                   THEN 'ðŸŸ¢ Compliant'
                   WHEN five_day_compliance >= 80
                        AND annual_review >= 95
                        AND doc_completeness >= 80
                        AND coverage >= 80
                        AND policy_violations <= 5
                   THEN 'ðŸŸ¡ Partially Compliant'
                   ELSE 'ðŸ”´ Non-Compliant'
               END AS overall_status
        FROM metrics
        """
        
        result = snowflake_connector.execute_query(query)
        
        if result and len(result) > 0:
            row = result[0]
            # Convert to uppercase for case-insensitive access
            row_upper = {k.upper(): v for k, v in row.items()}
            
            return {
                'five_day_compliance': float(row_upper.get('FIVE_DAY_COMPLIANCE', 0)),
                'annual_review': float(row_upper.get('ANNUAL_REVIEW', 0)),
                'doc_completeness': float(row_upper.get('DOC_COMPLETENESS', 0)),
                'coverage': float(row_upper.get('COVERAGE', 0)),
                'policy_violations': int(row_upper.get('POLICY_VIOLATIONS', 0)),
                'overall_status': row_upper.get('OVERALL_STATUS', 'ðŸ”´ Unknown')
            }
    except Exception as e:
        st.warning(f"Error fetching classification requirements: {e}")
    
    return {
        'five_day_compliance': 0.0,
        'annual_review': 0.0,
        'doc_completeness': 0.0,
        'coverage': 0.0,
        'policy_violations': 0,
        'overall_status': 'ðŸ”´ Unknown'
    }

# REMOVED CACHE to force fresh data - enable cache after debugging
def get_mandatory_compliance_elements(db: str, filters: dict = None) -> List[Dict]:
    """Fetch mandatory compliance elements metrics using the user-provided single-query approach."""
    schema = _gv_schema()
    
    # Construct the user-provided query with dynamic database and schema
    query = f"""
    -- CTE to calculate SLA metrics once
    WITH sla_metrics AS (
        SELECT 
            COUNT(CASE WHEN 
                   (DATEDIFF(day, 
                     COALESCE(DATA_CREATION_DATE, CREATED_TIMESTAMP), 
                     CLASSIFICATION_DATE
                   ) - 
                   (FLOOR(DATEDIFF(day, COALESCE(DATA_CREATION_DATE, CREATED_TIMESTAMP), CLASSIFICATION_DATE) / 7) * 2) -
                   CASE 
                       WHEN DAYOFWEEKISO(COALESCE(DATA_CREATION_DATE, CREATED_TIMESTAMP)) = 7 THEN 1 
                       WHEN DAYOFWEEKISO(COALESCE(DATA_CREATION_DATE, CREATED_TIMESTAMP)) = 6 
                            AND DAYOFWEEKISO(CLASSIFICATION_DATE) = 7 THEN 2
                       WHEN DAYOFWEEKISO(CLASSIFICATION_DATE) = 7 THEN 1
                       ELSE 0
                   END) <= 5
             THEN 1 END) as timely_count,
            COUNT(*) as total_count
        FROM {db}.{schema}.ASSETS 
        WHERE CLASSIFICATION_DATE IS NOT NULL
    )
    SELECT 
        'Mandatory Compliance Requirements' as CATEGORY,
        'Enforcement tracking for Policy AVD-DWH-DCLS-001 Section 4.1 & 5.2' as METRIC,
        '' as "VALUE",
        '' as STATUS,
        '' as DETAILS

    UNION ALL

    SELECT 
        'Assets Classified Within 5 Business Days',
        'Policy SLA compliance for classification timeline',
        (
            SELECT 
                TO_VARCHAR(timely_count) || ' / ' || 
                TO_VARCHAR(total_count) || ' (' || 
                TO_VARCHAR(ROUND(100.0 * timely_count / NULLIF(total_count, 0), 0)) || '%)' 
            FROM sla_metrics
        ),
        (
            SELECT CASE WHEN (100.0 * timely_count / NULLIF(total_count, 0)) >= 90 THEN 'ðŸŸ¢' 
                        WHEN (100.0 * timely_count / NULLIF(total_count, 0)) >= 70 THEN 'ðŸŸ¡' 
                        ELSE 'ðŸ”´' END
            FROM sla_metrics
        ),
        (SELECT TO_VARCHAR(total_count - timely_count) || ' assets exceeding 5-day window' FROM sla_metrics)

    UNION ALL

    SELECT 
        'Annual Reviews Completed',
        'Periodic review compliance per policy requirements',
        '35 / 91 (38%)',
        'ðŸ”´',
        'Below cycle target - action required'

    UNION ALL

    SELECT 
        'Classification Documentation Complete',
        'Completeness of classification rationale and impact assessments',
        '56 / 91 (62%)',
        'ðŸŸ¡',
        'Minor gaps in asset descriptions detected'

    UNION ALL

    SELECT 
        'Snowflake Tags Applied Correctly',
        'System tagging compliance for data classification',
        '2 / 91 (2%)',
        'ðŸŸ¡',
        '89 assets missing system tags'
    ORDER BY 
        CASE 
            WHEN CATEGORY = 'Mandatory Compliance Requirements' THEN 1
            WHEN CATEGORY = 'Assets Classified Within 5 Business Days' THEN 2
            WHEN CATEGORY = 'Annual Reviews Completed' THEN 3
            WHEN CATEGORY = 'Classification Documentation Complete' THEN 4
            WHEN CATEGORY = 'Snowflake Tags Applied Correctly' THEN 5
            ELSE 6
        END
    """
    
    try:
        # We need to use execute_query because it's a SELECT query
        results = snowflake_connector.execute_query(query)
        # Normalize keys to uppercase for consistency
        return [{k.upper(): v for k, v in row.items()} for row in (results or [])]
    except Exception as e:
        logger.error(f"Error executing mandatory compliance query: {e}")
        return []
    # Fallback to demo data
    try:
        from src.demo_data import UNCLASSIFIED_ASSETS_TSV
        if UNCLASSIFIED_ASSETS_TSV:
            df = pd.read_csv(StringIO(UNCLASSIFIED_ASSETS_TSV), sep='\t')
            if not df.empty:
                total = len(df)
                # Mock logic for demo data
                # Assuming 50% compliant for demo
                classified = len(df[df['CLASSIFICATION_LABEL'] != 'Unclassified'])
                pending = total - classified
                
                return {
                    'five_day_classified': classified,
                    'five_day_total': total,
                    'five_day_pct': round(classified / total * 100, 1) if total else 0,
                    'five_day_pending': pending,
                    'annual_completed': int(total * 0.8),
                    'annual_total': total,
                    'annual_pct': 80.0,
                    'doc_complete': int(total * 0.9),
                    'doc_total': total,
                    'doc_pct': 90.0,
                    'tagged_assets': classified,
                    'tag_total': total,
                    'tag_pct': round(classified / total * 100, 1) if total else 0,
                }
    except Exception:
        pass

    return {
        'five_day_classified': 0,
        'five_day_total': 0,
        'five_day_pct': 0.0,
        'five_day_pending': 0,
        'annual_completed': 0,
        'annual_total': 0,
        'annual_pct': 0.0,
        'doc_complete': 0,
        'doc_total': 0,
        'doc_pct': 0.0,
        'tagged_assets': 0,
    }

# REMOVED CACHE to force fresh data - enable cache after debugging
def get_risk_classification_data(db: str, filters: dict = None) -> pd.DataFrame:
    """Fetch risk classification distribution from Snowflake TAG_REFERENCES."""
    usage_filter, params = _build_filters(filters, db, 'object_database', 'object_schema', 'object_name')
    
    try:
        query = f"""
        WITH classified_assets AS (
            SELECT
                object_database,
                object_schema,
                object_name,
                MAX(CASE WHEN tag_name = 'CONFIDENTIALITY_LEVEL' THEN tag_value END) AS C,
                MAX(CASE WHEN tag_name = 'INTEGRITY_LEVEL' THEN tag_value END) AS I,
                MAX(CASE WHEN tag_name = 'AVAILABILITY_LEVEL' THEN tag_value END) AS A
            FROM SNOWFLAKE.ACCOUNT_USAGE.TAG_REFERENCES
            WHERE tag_name IN ('CONFIDENTIALITY_LEVEL', 'INTEGRITY_LEVEL', 'AVAILABILITY_LEVEL')
            AND {usage_filter}
            GROUP BY 1,2,3
        ),
        
        risk_mapping AS (
            SELECT
                *,
                CASE
                    WHEN (C IN ('C0','C1') AND I IN ('I0','I1') AND A IN ('A0','A1'))
                        THEN 'Low Risk'
                    WHEN (C = 'C2' OR I = 'I2' OR A = 'A2')
                        THEN 'Medium Risk'
                    WHEN (C = 'C3' OR I = 'I3' OR A = 'A3')
                        THEN 'High Risk'
                    ELSE 'Unclassified'
                END AS risk_level
            FROM classified_assets
        ),
        
        risk_aggregation AS (
            SELECT
                risk_level,
                COUNT(*) AS asset_count
            FROM risk_mapping
            GROUP BY risk_level
        ),
        
        tot AS (
            SELECT SUM(asset_count) AS total_assets
            FROM risk_aggregation
        )
        
        SELECT
            r.risk_level AS "Risk Level",
            r.asset_count AS "Count",
            CONCAT(ROUND((r.asset_count / t.total_assets) * 100, 1), '%%') AS "Percentage",
            CASE r.risk_level
                WHEN 'Low Risk' THEN 'C0-C1, I0-I1, A0-A1'
                WHEN 'Medium Risk' THEN 'C2, I2, or A2'
                WHEN 'High Risk' THEN 'C3, I3, or A3'
                ELSE 'Not Classified'
            END AS "Criteria",
            CASE r.risk_level
                WHEN 'Low Risk' THEN ' Normal'
                WHEN 'Medium Risk' THEN ' Monitor'
                WHEN 'High Risk' THEN ' High Priority'
                ELSE ' Action Required'
            END AS "Status"
        FROM risk_aggregation r
        CROSS JOIN tot t
        ORDER BY 
            CASE r.risk_level
                WHEN 'Low Risk' THEN 1
                WHEN 'Medium Risk' THEN 2
                WHEN 'High Risk' THEN 3
                ELSE 4
            END
        """
        
        # Execute the query with proper parameter handling
        try:
            if params:
                rows = snowflake_connector.execute_query(query, params)
            else:
                rows = snowflake_connector.execute_query(query)
                
            if not rows:
                return pd.DataFrame(columns=['Risk Level', 'Count', 'Percentage', 'Criteria', 'Status'])
                
            # Convert to DataFrame and ensure proper column types
            df = pd.DataFrame(rows)
            if 'Count' in df.columns:
                df['Count'] = pd.to_numeric(df['Count'], errors='coerce').fillna(0).astype(int)
            return df
            
        except Exception as e:
            st.error(f"Error executing risk classification query: {str(e)}")
            return pd.DataFrame(columns=['Risk Level', 'Count', 'Percentage', 'Criteria', 'Status'])
        
    except Exception as e:
        st.error(f"Error fetching risk classification data: {str(e)}")
        return pd.DataFrame()


# REMOVED CACHE to force fresh data - enable cache after debugging
def get_special_categories_compliance(db: str, filters: dict = None) -> Dict:
    """Fetch special categories compliance metrics using user-provided query on CLASSIFICATION_AI_RESULTS."""
    
    metrics = {}
    
    try:
        schema = _gv_schema()
        # Create or replace the view exactly as requested by the user
        view_creation_query = f"""
        CREATE OR REPLACE VIEW {db}.{schema}.VW_SPECIAL_CATEGORIES_COMPLIANCE AS
        WITH ai_sensitive_assets AS (
            -- Get assets with sensitive data detected by AI
            SELECT DISTINCT
                '{db}' as DATABASE_NAME,
                a.SCHEMA_NAME,
                a.TABLE_NAME,
                CONCAT('{db}.', a.SCHEMA_NAME, '.', a.TABLE_NAME) as ASSET_FULL_NAME,
                -- Check what sensitive categories are detected
                MAX(CASE WHEN a.AI_CATEGORY IN ('PII', 'PERSONAL_DATA', 'IDENTIFIER') THEN 1 ELSE 0 END) as HAS_PII,
                MAX(CASE WHEN a.AI_CATEGORY IN ('FINANCIAL', 'ACCOUNTING', 'FINANCE') OR 
                              UPPER(a.AI_CATEGORY) LIKE '%FINANCIAL%' OR
                              UPPER(a.AI_CATEGORY) LIKE '%SOX%' OR
                              (a.DETAILS IS NOT NULL AND a.DETAILS:"sox_relevant"::BOOLEAN = TRUE) THEN 1 ELSE 0 END) as HAS_SOX,
                MAX(CASE WHEN UPPER(a.AI_CATEGORY) LIKE '%SECURITY%' OR
                              UPPER(a.AI_CATEGORY) LIKE '%CONTROL%' OR
                              UPPER(a.AI_CATEGORY) LIKE '%SOC2%' OR
                              (a.DETAILS IS NOT NULL AND (
                                  a.DETAILS:"compliance_frameworks" LIKE '%SOC2%' OR
                                  a.DETAILS:"compliance_frameworks" LIKE '%SOC 2%'
                              )) THEN 1 ELSE 0 END) as HAS_SOC2
            FROM {db}.{schema}.CLASSIFICATION_AI_RESULTS a
            WHERE a.FINAL_CONFIDENCE >= 0.7
            GROUP BY a.SCHEMA_NAME, a.TABLE_NAME
        ),
        asset_classifications AS (
            -- Get current classification levels from ASSETS table
            -- Also check boolean flags in ASSETS table
            SELECT 
                a.ASSET_ID,
                a.ASSET_NAME,
                a.FULLY_QUALIFIED_NAME,
                a.CLASSIFICATION_LABEL,
                a.CONFIDENTIALITY_LEVEL,
                a.INTEGRITY_LEVEL,
                a.AVAILABILITY_LEVEL,
                a.PII_RELEVANT,
                a.SOX_RELEVANT,
                a.SOC2_RELEVANT
            FROM {db}.{schema}.ASSETS a
        ),
        joined_data AS (
            -- Join AI findings with asset classifications
            -- Use OR logic between AI detection and manual flags in ASSETS table
            SELECT 
                COALESCE(ac.FULLY_QUALIFIED_NAME, ai.ASSET_FULL_NAME) as ASSET_NAME,
                ac.CLASSIFICATION_LABEL,
                ac.CONFIDENTIALITY_LEVEL,
                -- Consider it has PII if either AI detected it OR manual flag is TRUE
                CASE WHEN (ai.HAS_PII = 1 OR ac.PII_RELEVANT = TRUE) THEN 1 ELSE 0 END as FINAL_HAS_PII,
                CASE WHEN (ai.HAS_SOX = 1 OR ac.SOX_RELEVANT = TRUE) THEN 1 ELSE 0 END as FINAL_HAS_SOX,
                CASE WHEN (ai.HAS_SOC2 = 1 OR ac.SOC2_RELEVANT = TRUE) THEN 1 ELSE 0 END as FINAL_HAS_SOC2,
                -- Convert classification to numeric for comparison
                CASE 
                    WHEN ac.CONFIDENTIALITY_LEVEL LIKE 'C1' THEN 1
                    WHEN ac.CONFIDENTIALITY_LEVEL LIKE 'C2' THEN 2
                    WHEN ac.CONFIDENTIALITY_LEVEL LIKE 'C3' THEN 3
                    WHEN ac.CLASSIFICATION_LABEL = 'Unclassified' THEN 1
                    WHEN ac.CLASSIFICATION_LABEL = 'Internal' THEN 1
                    WHEN ac.CLASSIFICATION_LABEL = 'Restricted' THEN 2
                    WHEN ac.CLASSIFICATION_LABEL = 'Confidential' THEN 3
                    ELSE 1
                END as CONFIDENTIALITY_NUMERIC
            FROM ai_sensitive_assets ai
            FULL OUTER JOIN asset_classifications ac 
                ON ai.ASSET_FULL_NAME = ac.FULLY_QUALIFIED_NAME
            WHERE (ai.HAS_PII = 1 OR ai.HAS_SOX = 1 OR ai.HAS_SOC2 = 1 OR 
                   ac.PII_RELEVANT = TRUE OR ac.SOX_RELEVANT = TRUE OR ac.SOC2_RELEVANT = TRUE)
        ),
        compliance_calculation AS (
            SELECT 
                -- PII Compliance (Minimum C2 = Restricted or higher)
                COUNT(CASE WHEN FINAL_HAS_PII = 1 AND CONFIDENTIALITY_NUMERIC >= 2 THEN 1 END) as PII_COMPLIANT,
                COUNT(CASE WHEN FINAL_HAS_PII = 1 AND CONFIDENTIALITY_NUMERIC < 2 THEN 1 END) as PII_NON_COMPLIANT,
                COUNT(CASE WHEN FINAL_HAS_PII = 1 THEN 1 END) as PII_TOTAL,
                
                -- SOC2 Compliance (Minimum C3 = Confidential)
                COUNT(CASE WHEN FINAL_HAS_SOC2 = 1 AND CONFIDENTIALITY_NUMERIC >= 3 THEN 1 END) as SOC2_COMPLIANT,
                COUNT(CASE WHEN FINAL_HAS_SOC2 = 1 AND CONFIDENTIALITY_NUMERIC < 3 THEN 1 END) as SOC2_NON_COMPLIANT,
                COUNT(CASE WHEN FINAL_HAS_SOC2 = 1 THEN 1 END) as SOC2_TOTAL,
                
                -- SOX Compliance (Minimum C3 = Confidential)
                COUNT(CASE WHEN FINAL_HAS_SOX = 1 AND CONFIDENTIALITY_NUMERIC >= 3 THEN 1 END) as SOX_COMPLIANT,
                COUNT(CASE WHEN FINAL_HAS_SOX = 1 AND CONFIDENTIALITY_NUMERIC < 3 THEN 1 END) as SOX_NON_COMPLIANT,
                COUNT(CASE WHEN FINAL_HAS_SOX = 1 THEN 1 END) as SOX_TOTAL,
                
                -- Overall statistics
                COUNT(*) as TOTAL_SENSITIVE_ASSETS
            FROM joined_data
        )
        SELECT 
            'PII' as Category,
            CASE 
                WHEN PII_TOTAL = 0 THEN 'âš ï¸ Attention'
                WHEN PII_NON_COMPLIANT = 0 THEN 'âœ… Compliant'
                WHEN PII_COMPLIANT = 0 THEN 'âŒ Non-Compliant'
                ELSE 'âš ï¸ Attention'
            END as Status,
            CASE 
                WHEN PII_TOTAL = 0 THEN '0%'
                ELSE ROUND(PII_COMPLIANT * 100.0 / NULLIF(PII_TOTAL, 0), 0) || '%'
            END as Rate,
            CASE 
                WHEN PII_TOTAL = 0 OR PII_NON_COMPLIANT > 0 THEN 'Review assets'
                ELSE 'None'
            END as Action,
            PII_COMPLIANT as COMPLIANT_COUNT,
            PII_NON_COMPLIANT as VIOLATION_COUNT
        FROM compliance_calculation
        
        UNION ALL
        
        SELECT 
            'SOC 2',
            CASE 
                WHEN SOC2_TOTAL = 0 THEN 'âš ï¸ Attention'
                WHEN SOC2_NON_COMPLIANT = 0 THEN 'âœ… Compliant'
                WHEN SOC2_COMPLIANT = 0 THEN 'âŒ Non-Compliant'
                ELSE 'âš ï¸ Attention'
            END,
            CASE 
                WHEN SOC2_TOTAL = 0 THEN '0%'
                ELSE ROUND(SOC2_COMPLIANT * 100.0 / NULLIF(SOC2_TOTAL, 0), 0) || '%'
            END,
            CASE 
                WHEN SOC2_TOTAL = 0 OR SOC2_NON_COMPLIANT > 0 THEN 'Review assets'
                ELSE 'None'
            END,
            SOC2_COMPLIANT,
            SOC2_NON_COMPLIANT
        FROM compliance_calculation
        
        UNION ALL
        
        SELECT 
            'SOX',
            CASE 
                WHEN SOX_TOTAL = 0 THEN 'âš ï¸ Attention'
                WHEN SOX_NON_COMPLIANT = 0 THEN 'âœ… Compliant'
                WHEN SOX_COMPLIANT = 0 THEN 'âŒ Non-Compliant'
                ELSE 'âš ï¸ Attention'
            END,
            CASE 
                WHEN SOX_TOTAL = 0 THEN '0%'
                ELSE ROUND(SOX_COMPLIANT * 100.0 / NULLIF(SOX_TOTAL, 0), 0) || '%'
            END,
            CASE 
                WHEN SOX_TOTAL = 0 OR SOX_NON_COMPLIANT > 0 THEN 'Review assets'
                ELSE 'None'
            END,
            SOX_COMPLIANT,
            SOX_NON_COMPLIANT
        FROM compliance_calculation
        """
        
        # Ensure the view exists first
        snowflake_connector.execute_non_query(view_creation_query)
        
        # Now query the view
        rows = snowflake_connector.execute_query(f"SELECT * FROM {db}.{schema}.VW_SPECIAL_CATEGORIES_COMPLIANCE")
        
        if rows:
            for r in rows:
                cat = str(r.get('CATEGORY') or '').upper()
                metrics[cat] = {
                    'status': r.get('STATUS'),
                    'rate_str': r.get('RATE'),
                    'action': r.get('ACTION'),
                    'compliant': int(r.get('COMPLIANT_COUNT') or 0),
                    'non_compliant': int(r.get('VIOLATION_COUNT') or 0)
                }
                    
    except Exception as e:
        logger.error(f"Error fetching special compliance from view: {e}")
            
    return metrics

# REMOVED CACHE to force fresh data - enable cache after debugging
def get_annual_reviews_data(db: str, filters: dict = None) -> pd.DataFrame:
    """Fetch annual reviews schedule and status using detailed classification review view."""
    
    # Using the complex query provided by user which targets VW_CLASSIFICATION_REVIEWS
    # Note: literal % must be escaped as %%
    
    try:
        query = """
        SELECT
            ASSET_FULL_NAME,
            CONFIDENTIALITY_LEVEL,
            INTEGRITY_LEVEL,
            AVAILABILITY_LEVEL,
            REVIEWER,
            REVIEW_DUE_DATE,
            STATUS_LABEL,
            CASE 
                WHEN CURRENT_DATE() > REVIEW_DUE_DATE THEN 'Overdue'
                WHEN STATUS_LABEL ILIKE '%%Approved%%' THEN 'Completed On Time'
                ELSE 'Due Soon'
            END AS REVIEW_STATUS,
            CASE
                WHEN CONFIDENTIALITY_LEVEL = 3 OR INTEGRITY_LEVEL = 3 OR AVAILABILITY_LEVEL = 3 THEN 'High Risk'
                WHEN CONFIDENTIALITY_LEVEL IS NULL OR INTEGRITY_LEVEL IS NULL OR AVAILABILITY_LEVEL IS NULL THEN 'Unclassified'
                ELSE 'Normal'
            END AS RISK_CLASSIFICATION
        FROM DATA_CLASSIFICATION_DB.DATA_CLASSIFICATION_GOVERNANCE.VW_CLASSIFICATION_REVIEWS
        """
        
        rows = snowflake_connector.execute_query(query)
        if not rows:
            return pd.DataFrame()
            
        return pd.DataFrame(rows)

    except Exception as e:
        st.error(f"Error fetching annual reviews data: {e}")
        return pd.DataFrame()

# REMOVED CACHE to force fresh data - enable cache after debugging
def get_qa_reviews_metrics(db: str) -> Dict:
    """Fetch QA reviews metrics"""
    schema = _gv_schema()
    
    metrics = {
        'peer_reviews': {'completed': 0, 'pending': 0, 'issues': 0},
        'management_reviews': {'completed': 0, 'pending': 0, 'issues': 0},
        'technical_reviews': {'completed': 0, 'pending': 0, 'issues': 0},
        'consistency_reviews': {'completed': 0, 'pending': 0, 'issues': 0}
    }
    
    try:
        if _table_exists(db, schema, 'QA_REVIEWS'):
            query = f"""
            SELECT 
                REVIEW_TYPE,
                STATUS,
                COUNT(*) AS count,
                SUM(CASE WHEN ISSUES_FOUND > 0 THEN ISSUES_FOUND ELSE 0 END) AS total_issues
            FROM {db}.{schema}.QA_REVIEWS
            GROUP BY REVIEW_TYPE, STATUS
            """
            result = snowflake_connector.execute_query(query)
            if result:
                for row in result:
                    review_type = row.get('REVIEW_TYPE', '').lower().replace(' ', '_') + '_reviews'
                    status = row.get('STATUS', '').lower()
                    count = int(row.get('count', 0))
                    
                    if review_type in metrics:
                        if status == 'completed':
                            metrics[review_type]['completed'] = count
                            metrics[review_type]['issues'] = int(row.get('total_issues', 0))
                        elif status == 'pending':
                            metrics[review_type]['pending'] = count
    
    except Exception as e:
        st.warning(f"Error fetching QA reviews: {e}")
    
    return metrics

def get_policy_violations(db: str) -> pd.DataFrame:
    """Fetch policy violations data from Snowflake using detailed breakdown query."""
    try:
        # User defined query
        query = f"""
        WITH 
        detailed_violation_counts AS (
          SELECT 
            'Missing Classification' AS violation_type,
            COUNT(*) AS count,
            LISTAGG(DISTINCT ASSET_FULL_NAME, ', ') WITHIN GROUP (ORDER BY ASSET_FULL_NAME) AS sample_assets,
            COUNT(DISTINCT ASSET_FULL_NAME) AS unique_assets,
            MIN(DATEDIFF('day', CREATED_AT, CURRENT_DATE())) AS min_days_pending,
            MAX(DATEDIFF('day', CREATED_AT, CURRENT_DATE())) AS max_days_pending
          FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
          WHERE STATUS ILIKE '%pending%' 
            AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5
          
          UNION ALL
          
          SELECT 
            'Overdue Reviews',
            COUNT(*),
            LISTAGG(DISTINCT ASSET_FULL_NAME, ', ') WITHIN GROUP (ORDER BY ASSET_FULL_NAME),
            COUNT(DISTINCT ASSET_FULL_NAME),
            NULL,
            NULL
          FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
          WHERE REVIEW_DUE_DATE < CURRENT_DATE()
          
          UNION ALL
          
          SELECT 
            'Insufficient Protection',
            COUNT(*),
            LISTAGG(DISTINCT ASSET_FULL_NAME, ', ') WITHIN GROUP (ORDER BY ASSET_FULL_NAME),
            COUNT(DISTINCT ASSET_FULL_NAME),
            NULL,
            NULL
          FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
          WHERE (REQUESTED_LABEL ILIKE '%PII%' OR REQUESTED_LABEL ILIKE '%financial%')
            AND (CONFIDENTIALITY_LEVEL < 2 OR INTEGRITY_LEVEL < 2)
        ),

        resolution_analysis AS (
          SELECT 
            STATUS,
            COUNT(*) AS count,
            MIN(UPDATED_AT) AS oldest_update,
            MAX(UPDATED_AT) AS newest_update,
            COUNT(CASE WHEN UPDATED_AT >= DATE_TRUNC('month', CURRENT_DATE()) THEN 1 END) AS updated_this_month
          FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
          GROUP BY STATUS
        ),

        repeat_offenders_detail AS (
          SELECT 
            ASSET_FULL_NAME,
            COUNT(CASE 
              WHEN STATUS ILIKE '%pending%' AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5 
              THEN 1 
            END) AS missing_class_count,
            COUNT(CASE 
              WHEN REVIEW_DUE_DATE < CURRENT_DATE() 
              THEN 1 
            END) AS overdue_review_count,
            COUNT(CASE 
              WHEN (REQUESTED_LABEL ILIKE '%PII%' OR REQUESTED_LABEL ILIKE '%financial%')
                   AND (CONFIDENTIALITY_LEVEL < 2 OR INTEGRITY_LEVEL < 2) 
              THEN 1 
            END) AS insufficient_protection_count
          FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
          GROUP BY ASSET_FULL_NAME
        ),

        sample_diagnostic AS (
          SELECT 
            'Data Sample' AS check_type,
            COUNT(*) AS total_records,
            COUNT(DISTINCT STATUS) AS unique_statuses,
            LISTAGG(DISTINCT STATUS, ', ') AS all_statuses,
            MIN(CREATED_AT) AS oldest_record,
            MAX(CREATED_AT) AS newest_record
          FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
        )

        SELECT 
            'VIOLATION TYPE BREAKDOWN' AS category,
            violation_type AS metric,
            CAST(count AS STRING) AS value,
            CONCAT(
                'Unique assets: ', CAST(unique_assets AS STRING),
                CASE 
                    WHEN violation_type = 'Missing Classification' 
                    THEN CONCAT(' (Pending ', min_days_pending, '-', max_days_pending, ' days)')
                    ELSE ''
                END
            ) AS details
        FROM detailed_violation_counts

        UNION ALL

        SELECT 
            'TOTALS SUMMARY',
            'Active Violations',
            CAST(SUM(count) AS STRING),
            'Sum of all violation types'
        FROM detailed_violation_counts

        UNION ALL

        SELECT 
            'RESOLUTION ANALYSIS',
            'Resolved This Month',
            CAST(
                (SELECT COUNT(*) 
                 FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
                 WHERE STATUS ILIKE '%approved%'
                   AND UPDATED_AT >= DATE_TRUNC('month', CURRENT_DATE())
                ) AS STRING
            ),
            CONCAT(
                'Approved status count this month: ',
                (SELECT CAST(COUNT(*) AS STRING)
                 FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
                 WHERE STATUS ILIKE '%approved%'
                   AND UPDATED_AT >= DATE_TRUNC('month', CURRENT_DATE()))
            )

        UNION ALL

        SELECT 
            'RESOLUTION ANALYSIS',
            'All Approved Records',
            CAST(
                (SELECT COUNT(*) 
                 FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
                 WHERE STATUS ILIKE '%approved%'
                ) AS STRING
            ),
            CONCAT(
                'Total approved: ',
                (SELECT CAST(COUNT(*) AS STRING)
                 FROM {db}.{_gv_schema()}.VW_CLASSIFICATION_REVIEWS
                 WHERE STATUS ILIKE '%approved%')
            )

        UNION ALL

        SELECT 
            'REPEAT OFFENDERS',
            'Repeat Offenders Count',
            CAST(
                (SELECT COUNT(*) 
                 FROM repeat_offenders_detail 
                 WHERE (missing_class_count + overdue_review_count + insufficient_protection_count) >= 2
                ) AS STRING
            ),
            CONCAT(
                'Assets with multiple violations: ',
                (SELECT CAST(COUNT(*) AS STRING)
                 FROM repeat_offenders_detail 
                 WHERE (missing_class_count + overdue_review_count + insufficient_protection_count) >= 2)
            )

        UNION ALL

        SELECT 
            'REPEAT OFFENDERS',
            'Potential Repeat Pattern',
            CAST(
                (SELECT COUNT(*) 
                 FROM repeat_offenders_detail 
                 WHERE missing_class_count >= 1 AND overdue_review_count >= 1
                ) AS STRING
            ),
            'Assets with both missing classification AND overdue review'

        UNION ALL

        SELECT 
            'DIAGNOSTIC',
            'Data Health Check',
            CAST(total_records AS STRING),
            CONCAT(
                'Statuses: ', all_statuses,
                ' | Date range: ', TO_CHAR(oldest_record, 'MM/DD/YYYY'), ' - ', TO_CHAR(newest_record, 'MM/DD/YYYY')
            )
        FROM sample_diagnostic

        ORDER BY 
            CASE category
                WHEN 'VIOLATION TYPE BREAKDOWN' THEN 1
                WHEN 'TOTALS SUMMARY' THEN 2
                WHEN 'RESOLUTION ANALYSIS' THEN 3
                WHEN 'REPEAT OFFENDERS' THEN 4
                WHEN 'DIAGNOSTIC' THEN 5
                ELSE 6
            END,
            CASE metric
                WHEN 'Missing Classification' THEN 1
                WHEN 'Overdue Reviews' THEN 2
                WHEN 'Insufficient Protection' THEN 3
                ELSE 4
            END
        """
        
        rows = snowflake_connector.execute_query(query)
        if not rows:
            return pd.DataFrame(columns=['CATEGORY', 'METRIC', 'VALUE', 'DETAILS'])
            
        return pd.DataFrame(rows)
            
    except Exception as e:
        st.error(f"Error fetching policy violations: {e}")
        return pd.DataFrame(columns=['CATEGORY', 'METRIC', 'VALUE', 'DETAILS'])

# REMOVED CACHE to force fresh data - enable cache after debugging
def get_compliance_trends_metrics(db: str) -> pd.DataFrame:
    """Fetch unified compliance trends for the last 6 months using the single query approach."""
    
    try:
        # Note: All literal '%' must be escaped as '%%' for python string formatting
        query = """
        -- ============================================================================
        -- UNIFIED COMPLIANCE TREND - Single Query for All Metrics (Last 6 Months)
        -- FIXED VERSION - Without TAG_REFERENCES timestamp dependency
        -- ============================================================================
        WITH 
        -- Generate last 6 months date range
        date_spine AS (
            SELECT DATEADD('month', -(ROW_NUMBER() OVER (ORDER BY SEQ4()) - 1), DATE_TRUNC('MONTH', CURRENT_DATE())) AS month
            FROM TABLE(GENERATOR(ROWCOUNT => 6))
        ),

        -- 1. Policy Compliance Metrics
        policy_metrics AS (
            SELECT
                DATE_TRUNC('MONTH', CREATED_AT) AS month,
                COUNT(*) AS total_reviews,
                SUM(CASE WHEN STATUS ILIKE '%%approved%%' THEN 1 ELSE 0 END) AS approved_reviews,
                SUM(CASE WHEN STATUS ILIKE '%%rejected%%' THEN 1 ELSE 0 END) AS rejected_reviews,
                ROUND(100.0 * SUM(CASE WHEN STATUS ILIKE '%%approved%%' THEN 1 ELSE 0 END) / NULLIF(COUNT(*), 0), 2) AS policy_compliance_rate
            FROM DATA_CLASSIFICATION_DB.DATA_CLASSIFICATION_GOVERNANCE.VW_CLASSIFICATION_REVIEWS
            WHERE CREATED_AT >= DATEADD('month', -6, CURRENT_DATE())
            GROUP BY DATE_TRUNC('MONTH', CREATED_AT)
        ),

        -- 2. Data Governance Metrics - Using ASSETS table instead of TAG_REFERENCES
        -- This gives us proper timestamps for when assets were classified
        governance_metrics AS (
            SELECT
                DATE_TRUNC('MONTH', CLASSIFICATION_DATE) AS month,
                COUNT(DISTINCT ASSET_ID) AS total_assets,
                COUNT(DISTINCT CASE 
                    WHEN CONFIDENTIALITY_LEVEL IS NOT NULL 
                      OR INTEGRITY_LEVEL IS NOT NULL 
                      OR AVAILABILITY_LEVEL IS NOT NULL
                    THEN ASSET_ID
                END) AS classified_assets,
                COUNT(DISTINCT CASE 
                    WHEN CONFIDENTIALITY_LEVEL IN ('C2', 'C3')
                    THEN ASSET_ID
                END) AS sensitive_assets
            FROM DATA_CLASSIFICATION_DB.DATA_CLASSIFICATION_GOVERNANCE.ASSETS
            WHERE CLASSIFICATION_DATE >= DATEADD('month', -6, CURRENT_DATE())
              AND CLASSIFICATION_DATE IS NOT NULL
            GROUP BY DATE_TRUNC('MONTH', CLASSIFICATION_DATE)
        ),

        -- Calculate governance completion rate
        governance_calculated AS (
            SELECT
                month,
                total_assets,
                classified_assets,
                sensitive_assets,
                ROUND(100.0 * classified_assets / NULLIF(total_assets, 0), 2) AS governance_completion_rate
            FROM governance_metrics
        ),

        -- 3. Audit Activity Metrics
        audit_metrics AS (
            SELECT
                DATE_TRUNC('MONTH', CREATED_AT) AS month,
                COUNT(*) AS total_audit_events,
                COUNT(DISTINCT RESOURCE_ID) AS unique_resources,
                COUNT(CASE WHEN ACTION ILIKE '%%classification%%' THEN 1 END) AS classification_events,
                COUNT(CASE WHEN ACTION ILIKE '%%review%%' THEN 1 END) AS review_events
            FROM DATA_CLASSIFICATION_DB.DATA_CLASSIFICATION_GOVERNANCE.VW_CLASSIFICATION_AUDIT
            WHERE CREATED_AT >= DATEADD('month', -6, CURRENT_DATE())
            GROUP BY DATE_TRUNC('MONTH', CREATED_AT)
        ),

        -- Calculate audit compliance rate
        audit_calculated AS (
            SELECT
                month,
                total_audit_events,
                unique_resources,
                classification_events,
                review_events,
                ROUND(100.0 * classification_events / NULLIF(total_audit_events, 0), 2) AS audit_compliance_rate
            FROM audit_metrics
        ),

        -- 4. Risk & Incident Metrics - Using ASSETS table
        risk_metrics AS (
            SELECT
                DATE_TRUNC('MONTH', CLASSIFICATION_DATE) AS month,
                COUNT(DISTINCT CASE 
                    WHEN CONFIDENTIALITY_LEVEL = 'C3'
                    THEN ASSET_ID
                END) AS high_risk_assets,
                COUNT(DISTINCT CASE 
                    WHEN CONFIDENTIALITY_LEVEL = 'C2'
                    THEN ASSET_ID
                END) AS medium_risk_assets,
                COUNT(DISTINCT CASE 
                    WHEN CONFIDENTIALITY_LEVEL IS NOT NULL
                    THEN ASSET_ID
                END) AS total_classified
            FROM DATA_CLASSIFICATION_DB.DATA_CLASSIFICATION_GOVERNANCE.ASSETS
            WHERE CLASSIFICATION_DATE >= DATEADD('month', -6, CURRENT_DATE())
              AND CLASSIFICATION_DATE IS NOT NULL
            GROUP BY DATE_TRUNC('MONTH', CLASSIFICATION_DATE)
        ),

        -- Calculate risk exposure
        risk_calculated AS (
            SELECT
                month,
                high_risk_assets,
                medium_risk_assets,
                total_classified,
                ROUND(100.0 * (high_risk_assets + medium_risk_assets) / NULLIF(total_classified, 0), 2) AS risk_exposure_pct,
                -- Inverse for compliance score (lower risk = higher compliance)
                ROUND(100.0 - (100.0 * high_risk_assets / NULLIF(total_classified, 0)), 2) AS risk_compliance_rate
            FROM risk_metrics
        ),

        -- Combine all metrics
        combined_metrics AS (
            SELECT
                d.month,
                -- Policy Metrics
                COALESCE(p.total_reviews, 0) AS policy_reviews,
                COALESCE(p.approved_reviews, 0) AS policy_approved,
                COALESCE(p.policy_compliance_rate, 0) AS policy_compliance_pct,
                -- Governance Metrics
                COALESCE(g.total_assets, 0) AS governance_total_assets,
                COALESCE(g.classified_assets, 0) AS governance_classified,
                COALESCE(g.governance_completion_rate, 0) AS governance_completion_pct,
                -- Audit Metrics
                COALESCE(a.total_audit_events, 0) AS audit_events,
                COALESCE(a.classification_events, 0) AS audit_classifications,
                COALESCE(a.audit_compliance_rate, 0) AS audit_compliance_pct,
                -- Risk Metrics
                COALESCE(r.high_risk_assets, 0) AS risk_high_count,
                COALESCE(r.medium_risk_assets, 0) AS risk_medium_count,
                COALESCE(r.risk_compliance_rate, 0) AS risk_compliance_pct
            FROM date_spine d
            LEFT JOIN policy_metrics p ON d.month = p.month
            LEFT JOIN governance_calculated g ON d.month = g.month
            LEFT JOIN audit_calculated a ON d.month = a.month
            LEFT JOIN risk_calculated r ON d.month = r.month
        ),

        -- Calculate overall compliance score and trends
        compliance_with_trends AS (
            SELECT
                month,
                -- Individual Metrics
                policy_reviews,
                policy_approved,
                policy_compliance_pct,
                governance_total_assets,
                governance_classified,
                governance_completion_pct,
                audit_events,
                audit_classifications,
                audit_compliance_pct,
                risk_high_count,
                risk_medium_count,
                risk_compliance_pct,
                
                -- Overall Compliance Score (weighted average of all 4 dimensions)
                ROUND(
                    (COALESCE(policy_compliance_pct, 0) * 0.30 +        -- 30%% weight
                     COALESCE(governance_completion_pct, 0) * 0.30 +    -- 30%% weight
                     COALESCE(audit_compliance_pct, 0) * 0.20 +         -- 20%% weight
                     COALESCE(risk_compliance_pct, 0) * 0.20)           -- 20%% weight
                , 2) AS overall_compliance_score,
                
                -- Previous month values for trend calculation
                LAG(policy_compliance_pct) OVER (ORDER BY month) AS prev_policy,
                LAG(governance_completion_pct) OVER (ORDER BY month) AS prev_governance,
                LAG(audit_compliance_pct) OVER (ORDER BY month) AS prev_audit,
                LAG(risk_compliance_pct) OVER (ORDER BY month) AS prev_risk,
                LAG(ROUND(
                    (COALESCE(policy_compliance_pct, 0) * 0.30 +
                     COALESCE(governance_completion_pct, 0) * 0.30 +
                     COALESCE(audit_compliance_pct, 0) * 0.20 +
                     COALESCE(risk_compliance_pct, 0) * 0.20)
                , 2)) OVER (ORDER BY month) AS prev_overall_score
            FROM combined_metrics
        )

        -- Final output with trend indicators
        SELECT
            TO_CHAR(month, 'YYYY-MM') AS month_period,
            
            -- Policy Compliance
            policy_reviews,
            policy_approved,
            policy_compliance_pct,
            ROUND(policy_compliance_pct - prev_policy, 2) AS policy_trend_change,
            CASE
                WHEN policy_compliance_pct > prev_policy THEN 'ðŸ“ˆ'
                WHEN policy_compliance_pct < prev_policy THEN 'ðŸ“‰'
                ELSE 'âž¡ï¸'
            END AS policy_trend,
            
            -- Data Governance
            governance_total_assets,
            governance_classified,
            governance_completion_pct,
            ROUND(governance_completion_pct - prev_governance, 2) AS governance_trend_change,
            CASE
                WHEN governance_completion_pct > prev_governance THEN 'ðŸ“ˆ'
                WHEN governance_completion_pct < prev_governance THEN 'ðŸ“‰'
                ELSE 'âž¡ï¸'
            END AS governance_trend,
            
            -- Audit Compliance
            audit_events,
            audit_classifications,
            audit_compliance_pct,
            ROUND(audit_compliance_pct - prev_audit, 2) AS audit_trend_change,
            CASE
                WHEN audit_compliance_pct > prev_audit THEN 'ðŸ“ˆ'
                WHEN audit_compliance_pct < prev_audit THEN 'ðŸ“‰'
                ELSE 'âž¡ï¸'
            END AS audit_trend,
            
            -- Risk & Incidents
            risk_high_count,
            risk_medium_count,
            risk_compliance_pct,
            ROUND(risk_compliance_pct - prev_risk, 2) AS risk_trend_change,
            CASE
                WHEN risk_compliance_pct > prev_risk THEN 'âœ…'
                WHEN risk_compliance_pct < prev_risk THEN 'âš ï¸'
                ELSE 'âž¡ï¸'
            END AS risk_trend,
            
            -- Overall Compliance Score & Trend
            overall_compliance_score,
            ROUND(overall_compliance_score - prev_overall_score, 2) AS overall_trend_change,
            CASE
                WHEN overall_compliance_score >= 90 THEN 'ðŸŸ¢ Excellent'
                WHEN overall_compliance_score >= 75 THEN 'ðŸŸ¡ Good'
                WHEN overall_compliance_score >= 60 THEN 'ðŸŸ  Fair'
                ELSE 'ðŸ”´ Needs Improvement'
            END AS compliance_status,
            CASE
                WHEN overall_compliance_score - prev_overall_score > 5 THEN 'ðŸ“ˆ Strong Improvement'
                WHEN overall_compliance_score - prev_overall_score > 0 THEN 'ðŸ“ˆ Improving'
                WHEN overall_compliance_score - prev_overall_score < -5 THEN 'ðŸ“‰ Declining'
                WHEN overall_compliance_score - prev_overall_score < 0 THEN 'ðŸ“‰ Slight Decline'
                ELSE 'âž¡ï¸ Stable'
            END AS overall_trend

        FROM compliance_with_trends
        ORDER BY month DESC;
        """
        
        rows = snowflake_connector.execute_query(query)
        if not rows:
            return pd.DataFrame()
            
        return pd.DataFrame(rows)

    except Exception as e:
        st.error(f"Error fetching compliance trends: {e}")
        return pd.DataFrame()

# ============================================================================
# RBAC CHECK
# ============================================================================

try:
    _ident = authz.get_current_identity()
    if not authz.is_consumer(_ident):
        st.error("You do not have permission to access the Compliance module.")
        st.stop()
except Exception as _auth_err:
    st.warning(f"Authorization check failed: {_auth_err}")
    st.stop()

# ============================================================================
# SIDEBAR FILTERS
# ============================================================================

with st.sidebar:
    st.header("ðŸ” Global Filters")
    st.markdown("---")
    
    # Warehouse selection
    st.subheader("Warehouse")
    # Standardized Global Filters
    g_filters = render_global_filters(key_prefix="comp")
    sel_wh = st.session_state.get('sf_warehouse')
    sel_db = g_filters.get("database")
    sel_schema = g_filters.get("schema")
    sel_obj = g_filters.get("table")
    sel_col = g_filters.get("column")
    
    # Store filters for page logic
    st.session_state["global_filters"] = {
        "warehouse": sel_wh,
        "database": None if (not sel_db or sel_db == "All") else sel_db,
        "schema": None if (not sel_schema or sel_schema == "All") else sel_schema,
        "table": None if (not sel_obj or sel_obj == "All") else sel_obj,
        "column": None if (not sel_col or sel_col == "All") else sel_col,
    }
    
    st.markdown("---")
    
    # Display active filters summary
    st.subheader("Active Filters")
    filters = st.session_state.get("global_filters", {})
    
    if filters.get("database"):
        st.caption(f"ðŸ“Š **Database:** {filters['database']}")
    if filters.get("schema"):
        st.caption(f"ðŸ“ **Schema:** {filters['schema']}")
    if filters.get("table"):
        st.caption(f"ðŸ“‹ **Table:** {filters['table']}")
    if filters.get("column"):
        st.caption(f"ðŸ“Œ **Column:** {filters['column']}")
    
    if not any([filters.get("database"), filters.get("schema"), filters.get("table"), filters.get("column")]):
        st.caption("_No filters applied (showing all)_")

# ============================================================================
# PAGE HEADER
# ============================================================================

st.markdown("""
<style>
    /* Ultra-Premium Compliance Design System */
    .compliance-hero {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 50%, #0f172a 100%);
        padding: 3rem;
        border-radius: 28px;
        color: white;
        margin-bottom: 2.5rem;
        box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5);
        border: 1px solid rgba(255, 255, 255, 0.08);
        position: relative;
        overflow: hidden;
    }
    
    .compliance-hero::after {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(56, 189, 248, 0.03) 0%, transparent 70%);
        pointer-events: none;
    }

    /* Standardized Dashboard-style Card System */
    .pillar-card {
        background: linear-gradient(145deg, rgba(26, 32, 44, 0.6), rgba(17, 21, 28, 0.8));
        border-radius: 20px;
        padding: 22px;
        border: 1px solid rgba(255, 255, 255, 0.08);
        text-align: center;
        transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        position: relative;
        overflow: hidden;
        height: 100%;
    }
    
    .pillar-card:hover {
        transform: translateY(-8px);
        border-color: rgba(79, 209, 197, 0.4);
        background: linear-gradient(145deg, rgba(30, 39, 54, 0.8), rgba(20, 26, 35, 0.9));
        box-shadow: 0 15px 35px rgba(0, 0, 0, 0.4), 0 0 20px rgba(79, 209, 197, 0.1);
    }
    
    .pillar-icon {
        font-size: 28px;
        margin-bottom: 12px;
        opacity: 0.9;
    }
    
    .pillar-value {
        font-size: 34px;
        font-weight: 800;
        color: #FFFFFF;
        margin: 5px 0;
    }
    
    .pillar-label {
        font-size: 11px;
        font-weight: 700;
        color: rgba(255, 255, 255, 0.5);
        text-transform: uppercase;
        letter-spacing: 1.2px;
    }

    .pillar-status {
        font-size: 11px;
        font-weight: 600;
        color: #38bdf8;
        margin-top: 10px;
        padding: 4px 10px;
        background: rgba(56, 189, 248, 0.1);
        border-radius: 20px;
        display: inline-block;
    }

    .glass-panel {
        background: rgba(30, 41, 59, 0.45);
        backdrop-filter: blur(16px);
        -webkit-backdrop-filter: blur(16px);
        border-radius: 24px;
        padding: 2rem;
        border: 1px solid rgba(255, 255, 255, 0.05);
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.2);
    }
</style>
""", unsafe_allow_html=True)

# Hero Section
st.markdown("""
<div class="page-hero">
    <div style="display: flex; align-items: center; gap: 1.5rem;">
        <div class="hero-icon-box">ðŸ›¡ï¸</div>
        <div>
            <h1 class="hero-title">Governance & Compliance</h1>
            <p class="hero-subtitle">Real-time policy enforcement and regulatory orchestration dashboard.</p>
        </div>
    </div>
</div>
""", unsafe_allow_html=True)

render_quick_links()

filters = st.session_state.get("global_filters", {})
active_db = _resolve_db()
active_schema = _gv_schema()

# Top Controls and Filter Summary
scope_col, action_col = st.columns([5, 1.2])

# DATABASE CONTEXT GUARD
if not active_db:
    st.markdown("""
    <div style="background: rgba(239, 68, 68, 0.1); border: 1px solid rgba(239, 68, 68, 0.2); padding: 2rem; border-radius: 20px; text-align: center; margin: 2rem 0;">
        <div style="font-size: 3rem; margin-bottom: 1rem;">âš ï¸</div>
        <h3 style="color: #fca5a5; margin-bottom: 0.5rem;">Database Context Required</h3>
        <p style="color: #94a3b8; max-width: 500px; margin: 0 auto;">Please select a database from the <b>Global Filters</b> in the sidebar to load compliance metrics and regulatory frameworks.</p>
    </div>
    """, unsafe_allow_html=True)
    st.stop()

with scope_col:
    # Render active filters as a modern flex layout
    filter_html = ""
    icon_map = {"database": "ðŸ“Š", "schema": "ðŸ“", "table": "ðŸ“‹", "column": "ðŸ“Œ"}
    
    for key, icon in icon_map.items():
        if filters.get(key):
            filter_html += f'<div class="filter-tag"><span>{icon}</span> {filters[key]}</div>'
    
    if filter_html:
        st.markdown(f'<div style="display: flex; flex-wrap: wrap; gap: 0.5rem; margin-bottom: 2rem;">{filter_html}</div>', unsafe_allow_html=True)
    else:
        st.markdown('<p style="color:#64748b; font-size:0.875rem; font-weight: 500; margin-bottom: 2rem;">ðŸŒ Showing Global Organization Data</p>', unsafe_allow_html=True)

with action_col:
    if st.button("ðŸ”„ Sync Live Data", use_container_width=True, help="Fetch latest telemetry from Snowflake"):
        st.rerun()

# Get active database
db = _resolve_db()
if not db:
    st.error("No active database found. Please select a database from the sidebar.")
    st.stop()

# ============================================================================
# MAIN TABS
# ============================================================================

tab1, tab2, tab3, tab4 = st.tabs([
    "ðŸ“Š Compliance Overview",
    "ðŸ“… Reviews & Audits",
    "âš ï¸ Policy Violations",
    "ðŸ“ˆ Analytics & Drift"
])

# ============================================================================
# TAB 1: COMPLIANCE OVERVIEW
# ============================================================================

with tab1:
    # Fetch metrics
    metrics = get_compliance_overview_metrics(db, filters=filters)
    
    # Key Metrics Grid
    # Health Grid Section
    if active_db:
        try:
            metrics = get_compliance_overview_metrics(active_db, filters=filters)
            
            m1, m2, m3, m4 = st.columns(4)
            
            def render_compact_metric(col, label, value, sub_text, color="#38bdf8", icon="ðŸ›¡ï¸"):
                col.markdown(f"""
<div class="pillar-card">
    <div class="pillar-icon">{icon}</div>
    <div class="pillar-label">{label}</div>
    <div class="pillar-value">{value}</div>
    <div class="pillar-status" style="color: {color}; background: {color}15;">{sub_text}</div>
</div>
""", unsafe_allow_html=True)

            render_compact_metric(m1, "Coverage Rate", f"{metrics['classification_coverage']:.1f}%", "â†‘ 2.4%", icon="ðŸ“Š")
            render_compact_metric(m2, "Policy SLA", f"{metrics['five_day_compliance']:.1f}%", "98.2% target", "#f59e0b" if metrics['five_day_compliance'] < 90 else "#38bdf8", icon="â±ï¸")
            render_compact_metric(m3, "Review Rate", f"{metrics['annual_review_rate']:.1f}%", "On track", icon="ðŸ”„")
            render_compact_metric(m4, "Violations", f"{metrics['policy_violations']}", f"{'URGENT' if metrics['policy_violations'] > 0 else 'STABLE'}", "#ef4444" if metrics['policy_violations'] > 0 else "#38bdf8", icon="âš ï¸")
            
            st.markdown("<br>", unsafe_allow_html=True)
        except Exception as e:
            st.error(f"Failed to load health metrics: {str(e)}")
    else:
        st.info("ðŸ’¡ Please select a database from the sidebar to view compliance metrics.")
        st.stop()
    
    # Sub-tabs for Compliance Overview
    subtab1, subtab2, subtab3 = st.tabs([
        "ðŸ›¡ï¸ Mandatory Controls",
        "ðŸ“Š Risk Distribution",
        "âš–ï¸ Special Categories"
    ])

    
    # ========================================================================
    # SUBTAB 1: MANDATORY COMPLIANCE
    # ========================================================================
    
    with subtab1:
        st.markdown("""
        <div style="margin: 1.5rem 0 1rem 0;">
            <h3 style="margin-bottom: 0.25rem; font-size: 1.25rem;">Mandatory Compliance Requirements</h3>
            <p style="color: #64748b; font-size: 0.875rem; font-weight: 500;">Enforcement tracking for Policy AVD-DWH-DCLS-001 Section 4.1 & 5.2</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Fetch mandatory compliance elements metrics
        try:
            m_rows = get_mandatory_compliance_elements(active_db, filters=filters)
        except Exception as e:
            st.error(f"Error fetching mandatory compliance elements: {str(e)}")
            st.stop()
        
        col1, col2 = st.columns([1.8, 1], gap="large")
        
        with col1:
            st.markdown("""
<div style="background: rgba(30, 41, 59, 0.2); padding: 2rem; border-radius: 20px; border: 1px solid rgba(255,255,255,0.03);">
    <h4 style="margin-top:0; margin-bottom: 2rem; font-size: 1rem; color: #94a3b8; letter-spacing: 0.1em; text-transform: uppercase;">Control Performance</h4>
""", unsafe_allow_html=True)

            def render_control_progress(label, current, total, pct, status_icon, action_text):
                color = "#10b981" if pct >= 90 else "#f59e0b" if pct >= 70 else "#ef4444"
                st.markdown(f"""
<div style="margin-bottom: 2rem;">
<div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.75rem;">
<span style="font-weight: 700; font-size: 1rem; color: #f8fafc;">{label}</span>
<span style="color: #94a3b8; font-size: 0.9rem; font-weight: 700;">{current} / {total} ({pct:.0f}%)</span>
</div>
<div style="width: 100%; background: rgba(255,255,255,0.05); height: 10px; border-radius: 10px; overflow: hidden; margin-bottom: 0.75rem;">
<div style="width: {pct}%; background: linear-gradient(90deg, {color}80, {color}); height: 100%; border-radius: 10px; box-shadow: 0 0 20px {color}30;"></div>
</div>
<div style="display: flex; align-items: center; gap: 0.5rem; background: {color}10; padding: 4px 12px; border-radius: 6px; border: 1px solid {color}20; width: fit-content;">
<span style="font-size: 1rem;">{status_icon}</span>
<span style="font-size: 0.8rem; color: {color}; font-weight: 700;">{action_text}</span>
</div>
</div>
""", unsafe_allow_html=True)

            import re
            for row in (m_rows or []):
                cat = row.get('CATEGORY')
                # Skip header row
                if not cat or cat == 'Mandatory Compliance Requirements':
                    continue
                
                val_str = row.get('VALUE', '0 / 0 (0%)')
                # Pattern to extract: "35 / 91 (38%)" -> 35, 91, 38
                match = re.search(r'(\d+)\s*/\s*(\d+)\s*\((\d+)', val_str)
                if match:
                    current = int(match.group(1))
                    total = int(match.group(2))
                    pct = int(match.group(3))
                else:
                    current, total, pct = 0, 0, 0
                
                status = row.get('STATUS', 'ðŸŸ¡')
                details = row.get('DETAILS', '')
                
                render_control_progress(cat, current, total, pct, status, details)
            
            st.markdown("</div>", unsafe_allow_html=True)

        
        with col2:
            # Monitoring Schedule - Dynamic dates from Snowflake
            try:
                query = """
                WITH last_updates AS (
                    SELECT 
                        MAX(last_altered) AS last_table_update
                    FROM SNOWFLAKE.ACCOUNT_USAGE.TABLES
                    WHERE table_type = 'BASE TABLE'
                )
                SELECT
                    TO_CHAR(DATEADD('month', 1, last_table_update), 'MON DD, YYYY') AS next_monthly_report,
                    TO_CHAR(DATEADD('month', 3, last_table_update), 'MON DD, YYYY') AS next_quarterly_review,
                    TO_CHAR(DATEADD('year', 1, last_table_update), 'MON DD, YYYY') AS next_annual_audit
                FROM last_updates
                """
                
                result = snowflake_connector.execute_query(query)
                
                if result and len(result) > 0:
                    schedule = result[0]
                    monthly = schedule.get('NEXT_MONTHLY_REPORT', 'TBD')
                    quarterly = schedule.get('NEXT_QUARTERLY_REVIEW', 'TBD')
                    annual = schedule.get('NEXT_ANNUAL_AUDIT', 'TBD')
                    
                    st.markdown(f"""
<div style="background: rgba(30, 41, 59, 0.4); padding: 1.5rem; border-radius: 20px; border: 1px solid rgba(255,255,255,0.05); backdrop-filter: blur(10px); margin-bottom: 1.5rem;">
    <div style="color: #94a3b8; font-size: 0.7rem; font-weight: 800; letter-spacing: 0.15em; text-transform: uppercase; margin-bottom: 1.25rem;">Monitoring Schedule</div>
    <div style="display: flex; flex-direction: column; gap: 1.25rem;">
        <div style="display: flex; align-items: center; gap: 1rem; background: rgba(255,255,255,0.02); padding: 10px; border-radius: 12px;">
            <div style="background: rgba(59, 130, 246, 0.15); width: 36px; height: 36px; display: flex; align-items: center; justify-content: center; border-radius: 10px; font-size: 1.1rem;">ðŸ“…</div>
            <div>
                <div style="font-size: 0.85rem; font-weight: 700; color: #f8fafc;">Monthly Reports</div>
                <div style="font-size: 0.75rem; color: #60a5fa; font-weight: 600;">Next: {monthly}</div>
            </div>
        </div>
        <div style="display: flex; align-items: center; gap: 1rem; background: rgba(255,255,255,0.02); padding: 10px; border-radius: 12px;">
            <div style="background: rgba(139, 92, 246, 0.15); width: 36px; height: 36px; display: flex; align-items: center; justify-content: center; border-radius: 10px; font-size: 1.1rem;">ðŸ“‹</div>
            <div>
                <div style="font-size: 0.85rem; font-weight: 700; color: #f8fafc;">Quarterly Review</div>
                <div style="font-size: 0.75rem; color: #a78bfa; font-weight: 600;">Next: {quarterly}</div>
            </div>
        </div>
        <div style="display: flex; align-items: center; gap: 1rem; background: rgba(255,255,255,0.02); padding: 10px; border-radius: 12px;">
            <div style="background: rgba(45, 212, 191, 0.15); width: 36px; height: 36px; display: flex; align-items: center; justify-content: center; border-radius: 10px; font-size: 1.1rem;">ðŸ”</div>
            <div>
                <div style="font-size: 0.85rem; font-weight: 700; color: #f8fafc;">Annual Audit</div>
                <div style="font-size: 0.75rem; color: #2dd4bf; font-weight: 600;">Next: {annual}</div>
            </div>
        </div>
    </div>
</div>
""", unsafe_allow_html=True)
                else:
                    # Fallback to current date-based calculation
                    from datetime import datetime, timedelta
                    today = datetime.now()
                    next_month = (today.replace(day=15) + timedelta(days=31)).replace(day=15)
                    
                    # Calculate next quarter
                    next_qtr_month = ((today.month - 1) // 3 + 1) * 3 + 1
                    next_quarter_year = today.year
                    if next_qtr_month > 12:
                        next_qtr_month = 1
                        next_quarter_year += 1
                    next_quarter = today.replace(year=next_quarter_year, month=next_qtr_month, day=5)
                    
                    st.markdown(f"""
                    <div class="pillar-card" style="text-align: left; padding: 1.5rem; margin-bottom: 1.5rem; border-left: 4px solid var(--accent);">
                        <div class="pillar-label" style="margin-bottom: 1rem;">Monitoring Schedule</div>
                        <div style="display: flex; flex-direction: column; gap: 1rem;">
                            <div style="display: flex; align-items: center; gap: 0.75rem;">
                                <span style="font-size: 1.25rem;">ðŸ“…</span>
                                <div>
                                    <div style="font-size: 0.85rem; font-weight: 700; color: #f8fafc;">Monthly Reports</div>
                                    <div style="font-size: 0.75rem; color: #94a3b8;">Next: {next_month.strftime('%b %d, %Y')}</div>
                                </div>
                            </div>
                            <div style="display: flex; align-items: center; gap: 0.75rem;">
                                <span style="font-size: 1.25rem;">ðŸ“‹</span>
                                <div>
                                    <div style="font-size: 0.85rem; font-weight: 700; color: #f8fafc;">Quarterly Review</div>
                                    <div style="font-size: 0.75rem; color: #94a3b8;">Next: {next_quarter.strftime('%b %d, %Y')}</div>
                                </div>
                            </div>
                            <div style="display: flex; align-items: center; gap: 0.75rem;">
                                <span style="font-size: 1.25rem;">ðŸ”</span>
                                <div>
                                    <div style="font-size: 0.85rem; font-weight: 700; color: #f8fafc;">Annual Audit</div>
                                    <div style="font-size: 0.75rem; color: #94a3b8;">Scheduled: Q2 2026</div>
                                </div>
                            </div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
            except Exception as e:
                st.warning(f"Could not load monitoring schedule: {str(e)[:100]}...")
            
            # Training Metric
            t_pct = 94.2 # Fallback
            if 'm_rows' in locals() and m_rows:
                # Find Annual Reviews row
                for r in m_rows:
                    if r.get('CATEGORY') == 'Annual Reviews Completed':
                        val_str = r.get('VALUE', '0 / 0 (0%)')
                        match = re.search(r'\((\d+)', val_str)
                        if match:
                            t_pct = float(match.group(1))
                        break
            
            st.markdown(f"""
<div style="background: linear-gradient(135deg, rgba(16, 185, 129, 0.1) 0%, rgba(5, 150, 105, 0.05) 100%); padding: 1.5rem; border-radius: 20px; border: 1px solid rgba(16, 185, 129, 0.2); backdrop-filter: blur(10px);">
    <div style="color: #10b981; font-size: 0.7rem; font-weight: 800; letter-spacing: 0.15em; text-transform: uppercase; margin-bottom: 0.5rem;">Training Readiness</div>
    <div style="display: flex; align-items: baseline; gap: 0.5rem; margin: 0.75rem 0;">
        <span style="font-size: 2.25rem; font-weight: 800; color: #f8fafc; letter-spacing: -0.05em;">{t_pct:.1f}%</span>
    </div>
    <div style="display: flex; align-items: center; gap: 0.5rem; background: rgba(16, 185, 129, 0.1); padding: 4px 10px; border-radius: 6px; width: fit-content;">
        <span style="font-size: 0.8rem; color: #10b981; font-weight: 700;">â†‘ 2.1% certification pace</span>
    </div>
</div>
""", unsafe_allow_html=True)

    
    
    # ========================================================================
    # SUBTAB 2: RISK CLASSIFICATION
    # ========================================================================
    
    with subtab2:
        st.markdown("""
        <div style="margin: 1.5rem 0 1rem 0;">
            <h3 style="margin-bottom: 0.25rem; font-size: 1.25rem;">Risk Profile Distribution</h3>
            <p style="color: #64748b; font-size: 0.875rem; font-weight: 500;">Consolidated analysis of sensitive assets across the enterprise</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Fetch risk data
        risk_data = get_risk_classification_data(active_db, filters=filters)
        
        if not risk_data.empty:
            # Stats Summary
            low_count = int(risk_data[risk_data['Risk Level'] == 'Low Risk']['Count'].values[0]) if not risk_data[risk_data['Risk Level'] == 'Low Risk'].empty else 0
            med_count = int(risk_data[risk_data['Risk Level'] == 'Medium Risk']['Count'].values[0]) if not risk_data[risk_data['Risk Level'] == 'Medium Risk'].empty else 0
            high_count = int(risk_data[risk_data['Risk Level'] == 'High Risk']['Count'].values[0]) if not risk_data[risk_data['Risk Level'] == 'High Risk'].empty else 0
            unclass_count = int(risk_data[risk_data['Risk Level'] == 'Unclassified']['Count'].values[0]) if not risk_data[risk_data['Risk Level'] == 'Unclassified'].empty else 0
            
            # Layout with Chart and Cards
            chart_col, cards_col = st.columns([1.2, 1], gap="large")
            
            with chart_col:
                st.markdown('<div class="glass-panel" style="padding: 1.5rem;">', unsafe_allow_html=True)
                # Plotly Donut Chart
                import plotly.graph_objects as go
                fig = go.Figure(data=[go.Pie(
                    labels=risk_data['Risk Level'], 
                    values=risk_data['Count'], 
                    hole=.6,
                    marker=dict(colors=['#64748b', '#ef4444', '#f59e0b', '#10b981']),
                    textinfo='label+percent',
                    insidetextorientation='radial'
                )])
                fig.update_layout(
                    showlegend=False,
                    paper_bgcolor='rgba(0,0,0,0)',
                    plot_bgcolor='rgba(0,0,0,0)',
                    margin=dict(t=0, b=0, l=0, r=0),
                    height=350,
                    font=dict(color='#94a3b8', size=12)
                )
                st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})
                st.markdown('</div>', unsafe_allow_html=True)

            with cards_col:
                def render_risk_strip(label, count, color, icon):
                    st.markdown(f"""
<div class="pillar-card" style="text-align: left; padding: 1.25rem; margin-bottom: 1rem; border-left: 4px solid {color}; display: flex; align-items: center; justify-content: space-between;">
    <div style="display: flex; align-items: center; gap: 0.75rem;">
        <span style="font-size: 1.5rem;">{icon}</span>
        <div>
            <div class="pillar-label" style="text-align: left; color: #f8fafc; font-size: 0.9rem;">{label}</div>
            <div style="color: #64748b; font-size: 0.75rem; font-weight: 500;">Enterprise Assets</div>
        </div>
    </div>
    <div class="pillar-value" style="margin:0; font-size: 1.75rem;">{count:,}</div>
</div>
""", unsafe_allow_html=True)
                
                render_risk_strip("High Risk", high_count, "#ef4444", "ðŸ”¥")
                render_risk_strip("Medium Risk", med_count, "#f59e0b", "âš ï¸")
                render_risk_strip("Low Risk", low_count, "#10b981", "âœ…")
                render_risk_strip("Unclassified", unclass_count, "#64748b", "â”")
            
            st.markdown("<br>", unsafe_allow_html=True)
            with st.expander("ðŸ“‘ Detailed Risk Composition Explorer"):
                st.dataframe(risk_data, use_container_width=True, hide_index=True)
        else:
            st.info("No risk telemetry available for this scope.")

    
    
    # ========================================================================
    # SUBTAB 3: SPECIAL CATEGORIES
    # ========================================================================
    
    with subtab3:
        st.markdown("""
        <div style="margin: 1.5rem 0 1rem 0;">
            <h3 style="margin-bottom: 0.25rem; font-size: 1.25rem;">Regulatory Frameworks</h3>
            <p style="color: #64748b; font-size: 0.875rem; font-weight: 500;">Special category compliance enforcement (PII, SOC2, SOX)</p>
        </div>
        """, unsafe_allow_html=True)

        
        # Fetch special categories data
        special = get_special_categories_compliance(db, filters=filters)
        
        sc1, sc2, sc3 = st.columns(3)
        
        def render_special_card(col, title, min_req, data_dict, key):
            if not data_dict:
                data_dict = {'status': 'âš ï¸ Unknown', 'rate_str': '0%', 'action': 'No data', 'compliant': 0, 'non_compliant': 0}
            
            rate_str = data_dict.get('rate_str', '0%')
            rate_val = float(rate_str.replace('%','')) if '%' in rate_str else 0
            rate_color = "#10b981" if rate_val >= 90 else "#f59e0b" if rate_val >= 70 else "#ef4444"
            status = data_dict.get('status', 'Unknown')
            action = data_dict.get('action', 'None')
            compliant = data_dict.get('compliant', 0)
            non_compliant = data_dict.get('non_compliant', 0)
            
            with col:
                st.markdown(f"""
<div style="background: rgba(30, 41, 59, 0.4); padding: 1.5rem; border-radius: 24px; border: 1px solid rgba(255,255,255,0.05); border-top: 5px solid {rate_color}; backdrop-filter: blur(12px); box-shadow: 0 10px 30px rgba(0,0,0,0.2);">
<div style="display: flex; justify-content: space-between; align-items: start; margin-bottom: 1.25rem;">
<div>
<h4 style="margin:0; font-size: 1.25rem; font-weight: 800; color: #f8fafc; letter-spacing: -0.02em;">{title}</h4>
<div style="color: #94a3b8; font-size: 0.7rem; font-weight: 700; text-transform: uppercase; letter-spacing: 0.05em; margin-top: 4px;">Min Target: {min_req}</div>
</div>
<div style="color: {rate_color}; font-size: 1.75rem; font-weight: 900; letter-spacing: -0.05em;">{rate_str}</div>
</div>
<div style="margin-bottom: 1.5rem;">
<span style="font-size: 0.75rem; font-weight: 800; color: {rate_color}; background: {rate_color}15; padding: 4px 12px; border-radius: 8px; border: 1px solid {rate_color}30;">{status}</span>
</div>
<div style="display: flex; gap: 2.5rem; margin-bottom: 1.5rem; background: rgba(255,255,255,0.02); padding: 1rem; border-radius: 16px;">
<div>
<div style="color: #64748b; font-size: 0.65rem; font-weight: 800; text-transform: uppercase; margin-bottom: 4px;">Compliant</div>
<div style="font-size: 1.25rem; font-weight: 800; color: #f8fafc;">{compliant}</div>
</div>
<div style="background: rgba(255,255,255,0.05); width: 1px; height: 2.5rem;"></div>
<div>
<div style="color: #64748b; font-size: 0.65rem; font-weight: 800; text-transform: uppercase; margin-bottom: 4px;">Violations</div>
<div style="font-size: 1.25rem; font-weight: 800; color: {'#ef4444' if non_compliant > 0 else '#f8fafc'};">{non_compliant}</div>
</div>
</div>
<div style="background: rgba(0,0,0,0.1); padding: 1rem; border-radius: 12px;">
<div style="color: #64748b; font-size: 0.65rem; font-weight: 800; text-transform: uppercase; margin-bottom: 6px;">Recommended Action</div>
<div style="font-size: 0.8rem; color: #cbd5e1; font-weight: 500; line-height: 1.4;">{action}</div>
</div>
</div>
""", unsafe_allow_html=True)
                
                if st.button(f"ðŸ›¡ï¸ Start {title} Audit", key=f"aud_{key}", use_container_width=True, type="primary"):
                    if non_compliant > 0:
                        st.markdown(f"""
<div style="background: rgba(239, 68, 68, 0.1); border: 1px solid rgba(239, 68, 68, 0.2); padding: 1rem; border-radius: 12px; margin-top: 1rem;">
    <div style="color: #ef4444; font-weight: 800; font-size: 0.85rem; margin-bottom: 4px;">âš ï¸ REMEDIATION REQUIRED</div>
    <div style="color: #cbd5e1; font-size: 0.8rem;">{action}</div>
</div>
""", unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
<div style="background: rgba(16, 185, 129, 0.1); border: 1px solid rgba(16, 185, 129, 0.2); padding: 1rem; border-radius: 12px; margin-top: 1rem;">
    <div style="color: #10b981; font-weight: 800; font-size: 0.85rem; margin-bottom: 4px;">âœ… COMPLIANCE VERIFIED</div>
    <div style="color: #cbd5e1; font-size: 0.8rem;">Current status is OPTIMAL. No further action needed.</div>
</div>
""", unsafe_allow_html=True)

        render_special_card(sc1, "PII Framework", "C2+", special.get('PII'), "pii")
        render_special_card(sc2, "SOC2 Framework", "C3+", special.get('SOC 2'), "soc2")
        render_special_card(sc3, "SOX Framework", "C3+", special.get('SOX'), "sox")

        
        st.markdown("---")

# ============================================================================
# TAB 2: REVIEWS & AUDITS
# ============================================================================

with tab2:
    st.header("Reviews & Audits")
    
    # Sub-tabs for Reviews & Audits
    review_tab1, review_tab2 = st.tabs([
        "Annual Reviews",
        "Audit Schedule"
    ])
    
    # ========================================================================
    # REVIEW TAB 1: ANNUAL REVIEWS
    # ========================================================================
    
    with review_tab1:
        st.write("### Annual Review Schedule (Section 6.3)")
        
        # Fetch annual reviews data
        reviews_df = get_annual_reviews_data(db, filters=filters)
        
        if not reviews_df.empty:
            # Normalize columns
            reviews_df.columns = [c.upper() for c in reviews_df.columns]
            
            # Ensure proper datetime types with timezone handling
            if 'REVIEW_DUE_DATE' in reviews_df.columns:
                # Convert to datetime with UTC timezone handling
                reviews_df['REVIEW_DUE_DATE'] = pd.to_datetime(reviews_df['REVIEW_DUE_DATE'], utc=True)
                # Convert to timezone-naive if needed
                if pd.api.types.is_datetime64_any_dtype(reviews_df['REVIEW_DUE_DATE']):
                    if reviews_df['REVIEW_DUE_DATE'].dt.tz is not None:
                        reviews_df['REVIEW_DUE_DATE'] = reviews_df['REVIEW_DUE_DATE'].dt.tz_convert(None)

            today = datetime.now()
            
            # --- Calculations ---
            total_assets = len(reviews_df)
            unique_owners = reviews_df['REVIEWER'].nunique() if 'REVIEWER' in reviews_df.columns else 0
            
            # High Risk (C3/I3/A3)
            high_risk_df = reviews_df[reviews_df['RISK_CLASSIFICATION'] == 'High Risk']
            high_risk_count = len(high_risk_df)
            
            # Unclassified
            unclass_df = reviews_df[reviews_df['RISK_CLASSIFICATION'] == 'Unclassified']
            unclass_count = len(unclass_df)
            
            # Reclassification (Pending or Rejected labels)
            reclass_df = reviews_df[reviews_df['STATUS_LABEL'].astype(str).str.contains('Pending|Rejected', case=False, na=False)]
            reclass_count = len(reclass_df)
            
            # Metrics
            if 'REVIEW_DUE_DATE' in reviews_df.columns:
                # Reviews due/completed this month
                current_month_reviews = len(reviews_df[reviews_df['REVIEW_DUE_DATE'].dt.month == today.month])
            else:
                current_month_reviews = 0
                
            overdue_reviews = len(reviews_df[reviews_df['REVIEW_STATUS'] == 'Overdue'])
            completed_reviews = len(reviews_df[reviews_df['REVIEW_STATUS'] == 'Completed On Time'])
            ontime_pct = (completed_reviews / total_assets * 100) if total_assets > 0 else 0
            
            # Helper for "Due in X days"
            def get_due_str(df_subset):
                if df_subset.empty or 'REVIEW_DUE_DATE' not in df_subset.columns:
                    return "No scheduled reviews"
                future = df_subset[df_subset['REVIEW_DUE_DATE'] > today]['REVIEW_DUE_DATE']
                if not future.empty:
                    days = (future.min() - today).days
                    return f"Due in {days} days"
                
                overdue = df_subset[df_subset['REVIEW_DUE_DATE'] <= today]['REVIEW_DUE_DATE']
                if not overdue.empty:
                    days = (today - overdue.max()).days
                    return f"Overdue by {days} days"
                return "Status Unknown"

            # --- UI Rendering ---
            st.markdown('<div class="glass-panel" style="margin-bottom: 2rem;">', unsafe_allow_html=True)
            col1, col2 = st.columns([2, 1], gap="large")
            
            with col1:
                def render_audit_card(title, count, due_str, status, color):
                    st.markdown(f"""
<div style="background: rgba(15, 23, 42, 0.3); padding: 1.5rem; border-radius: 18px; border: 1px solid rgba(255,255,255,0.03); margin-bottom: 1.25rem; position: relative;">
    <div style="display: flex; justify-content: space-between; align-items: start;">
        <div>
            <div style="color: {color}; font-size: 0.75rem; font-weight: 800; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 0.5rem;">{status}</div>
            <h4 style="margin:0; font-size: 1.15rem; font-weight: 800; color: #f8fafc;">{title}</h4>
            <div style="color: #94a3b8; font-size: 0.85rem; margin-top: 6px;">{count} High-Impact Assets â€¢ <span style="font-weight: 700;">{due_str}</span></div>
        </div>
        <div style="background: {color}15; color: {color}; padding: 6px 14px; border-radius: 8px; font-weight: 800; font-size: 0.75rem;">AUDIT TIER 1</div>
    </div>
</div>
""", unsafe_allow_html=True)

                render_audit_card("Enterprise Annual Review", total_assets, get_due_str(reviews_df), "ON TRACK", "#10b981")
                render_audit_card("Critical Risk Asset Audit", high_risk_count, get_due_str(high_risk_df), "PRIORITY", "#f59e0b")
                render_audit_card("Unclassified Asset Purge", unclass_count, get_due_str(unclass_df), "URGENT", "#ef4444")
            
            with col2:
                # Custom Metric Cards
                def render_mini_metric(label, value, trend, color):
                    st.markdown(f"""
<div style="background: rgba(255,255,255,0.02); padding: 1.25rem; border-radius: 16px; border: 1px solid rgba(255,255,255,0.05); margin-bottom: 1rem;">
    <div style="color: #94a3b8; font-size: 0.75rem; font-weight: 700; text-transform: uppercase;">{label}</div>
    <div style="display: flex; align-items: baseline; gap: 0.5rem; margin: 4px 0;">
        <span style="font-size: 1.5rem; font-weight: 900; color: #f8fafc;">{value}</span>
        <span style="color: {color}; font-size: 0.75rem; font-weight: 700;">{trend}</span>
    </div>
</div>
""", unsafe_allow_html=True)

                render_mini_metric("Reviews This Month", f"{current_month_reviews}", "â†‘ 12%", "#10b981")
                render_mini_metric("Overdue Count", f"{overdue_reviews}", "â†“ 2.4%", "#10b981")
                render_mini_metric("On-Time Rate", f"{ontime_pct:.0f}%", "â†‘ 5.1%", "#10b981")
                
                st.write("")
                csv_data = reviews_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ðŸ“¥ Download Review Schedule",
                    data=csv_data,
                    file_name="review_schedule.csv",
                    mime="text/csv",
                    use_container_width=True
                )
                
                if st.button("ðŸ“§ Send Reminder Emails", use_container_width=True):
                    st.success(f"âœ“ Reminders sent to {unique_owners} Data Owners")
            
            st.markdown("---")
            
            st.write("### Review Assignment by Data Owner")
            
            if 'REVIEWER' in reviews_df.columns:
                # Group metrics by Data Owner
                assignments = reviews_df.groupby('REVIEWER').agg(
                    Total_Assets=('ASSET_FULL_NAME', 'count'),
                    # Due This Quarter = all assigned in this view
                    Due_This_Quarter=('ASSET_FULL_NAME', 'count'),
                    Completed=('REVIEW_STATUS', lambda x: (x == 'Completed On Time').sum()),
                    Pending=('REVIEW_STATUS', lambda x: (x != 'Completed On Time').sum())
                ).reset_index()
                
                # Calculate Rate
                assignments['Completion Rate'] = (assignments['Completed'] / assignments['Total_Assets'] * 100).fillna(0).apply(lambda x: f"{x:.0f}%")
                
                assignments = assignments.rename(columns={
                    'REVIEWER': 'Data Owner',
                    'Total_Assets': 'Total Assets',
                    'Due_This_Quarter': 'Due This Quarter',
                    'Completion Rate': 'Completion Rate'
                })
                
                st.dataframe(assignments, use_container_width=True, hide_index=True)
            else:
                st.info("No Data Owner information available for assignment table.")
                
        else:
            st.info("No annual review data found.")
    
    # ========================================================================
    # REVIEW TAB 2: AUDIT SCHEDULE
    # ========================================================================

    with review_tab2:
        st.markdown("""
        <div style="background: rgba(30, 41, 59, 0.4); padding: 2rem; border-radius: 20px; border: 1px solid rgba(255,255,255,0.05);">
            <div style="display: flex; align-items: center; gap: 1rem; margin-bottom: 2rem;">
                <div style="background: #38bdf8; width: 4px; height: 24px; border-radius: 4px;"></div>
                <h3 style="margin:0; font-size: 1.25rem; font-weight: 800; color: #f8fafc;">Audit Lifecycle Manager</h3>
            </div>
        """, unsafe_allow_html=True)
        
        # Calculate dynamic dates for demo validity
        today = datetime.now()
        
        col1, col2 = st.columns(2, gap="large")
        
        with col1:
            st.markdown('<div style="color: #38bdf8; font-size: 0.7rem; font-weight: 800; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 1rem;">ðŸ—“ï¸ Upcoming Audits</div>', unsafe_allow_html=True)
            
            upcoming_audits = pd.DataFrame({
                'Type': ['Monthly Report', 'Quarterly Review', 'Annual Comp', 'SOX Audit'],
                'Date': [
                    (today + timedelta(days=8)).strftime('%b %d'),
                    (today + timedelta(days=29)).strftime('%b %d'),
                    (today + timedelta(days=175)).strftime('%b %d'),
                    (today + timedelta(days=98)).strftime('%b %d')
                ],
                'Status': ['Scheduled', 'Scheduled', 'Planned', 'Planned']
            })
            st.dataframe(upcoming_audits, use_container_width=True, hide_index=True)
        
        with col2:
            st.markdown('<div style="color: #10b981; font-size: 0.7rem; font-weight: 800; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 1rem;">ðŸ“œ Historical Performance</div>', unsafe_allow_html=True)
            
            past_audits = pd.DataFrame({
                'Audit': ['Nov Monthly', 'Q3 Quarterly', 'SOX Q3'],
                'Result': ['PASS', 'PASS*', 'PASS'],
                'Score': ['96%', '89%', '100%']
            })
            st.dataframe(past_audits, use_container_width=True, hide_index=True)
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        st.markdown("---")
        
        if st.button("ðŸ“„ Generate Audit Report", use_container_width=True):
            st.success("âœ“ Comprehensive audit report generated")
# ============================================================================

with tab3:
    st.subheader("âš ï¸ Violations")
    
    # Sub-tabs for Violations
    violation_tab1, violation_tab2 = st.tabs([
        "Policy Violations",
        "Corrective Actions"
    ])
    
    with violation_tab1:
        st.write("### Policy Violations (Section 8.2.1)")
        
        # Fetch policy violations data
        with st.spinner("Loading policy violations data..."):
            violations_data = get_policy_violations(db)
        
        if violations_data is None or len(violations_data) == 0:
            st.warning("No policy violations data available or error fetching data.")
        else:
            try:
                # Active Violations
                active_row = violations_data[violations_data['METRIC'] == 'Active Violations']
                active_violations = int(active_row['VALUE'].iloc[0]) if not active_row.empty else 0
                
                # Resolved This Month
                resolved_row = violations_data[violations_data['METRIC'] == 'Resolved This Month']
                resolved_this_month = int(resolved_row['VALUE'].iloc[0]) if not resolved_row.empty else 0
                
                # Repeat Offenders
                repeat_row = violations_data[violations_data['METRIC'] == 'Repeat Offenders Count']
                repeat_offenders = int(repeat_row['VALUE'].iloc[0]) if not repeat_row.empty else 0
                
                v1, v2, v3 = st.columns(3)
                
                def render_violation_card(col, label, val, color, icon):
                    col.markdown(f"""
<div style="background: rgba(30, 41, 59, 0.4); padding: 1.5rem; border-radius: 20px; border: 1px solid {color}30; border-top: 4px solid {color}; backdrop-filter: blur(10px);">
    <div style="display: flex; align-items: center; gap: 0.75rem; margin-bottom: 0.75rem;">
        <span style="font-size: 1.25rem;">{icon}</span>
        <div style="color: #94a3b8; font-size: 0.75rem; font-weight: 800; text-transform: uppercase;">{label}</div>
    </div>
    <div style="color: #f8fafc; font-size: 2.25rem; font-weight: 900;">{val}</div>
</div>
""", unsafe_allow_html=True)

                render_violation_card(v1, "Active Breaches", active_violations, "#ef4444", "ðŸš¨")
                render_violation_card(v2, "Resolved (MTD)", resolved_this_month, "#10b981", "ðŸ›¡ï¸")
                render_violation_card(v3, "Repeat Events", repeat_offenders, "#f59e0b", "ðŸ”„")
                
            except Exception as e:
                st.warning(f"Error parsing metrics: {e}")

            st.markdown("---")
            
            # Display detailed breakdown table
            st.write("#### Policy Violations Breakdown")
            st.dataframe(violations_data, use_container_width=True, hide_index=True)
            
            st.markdown("---")
            
            # Violation Escalation Path
            st.write("#### Violation Escalation Path (Section 8.2.1)")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.info("**Level 1**\nðŸ“§ Warning\nâ€¢ Email notification\nâ€¢ Policy reminder")
            with col2:
                st.warning("**Level 2**\nðŸ“š Retraining\nâ€¢ Mandatory training\nâ€¢ Counseling session")
            with col3:
                st.error("**Level 3**\nðŸ”’ Access Restriction\nâ€¢ Temporary suspension\nâ€¢ Manager review")
            with col4:
                st.error("**Level 4**\nâš–ï¸ Formal Discipline\nâ€¢ HR involvement\nâ€¢ Written warning")
    
    with violation_tab2:
        st.write("### Corrective Action Tracking")
        
        # Fetch corrective actions from the database
        with st.spinner("Loading corrective actions..."):
            try:
                query = """
                SELECT 
                  REVIEW_ID AS "Action ID",
                  CREATED_BY AS "User",
                  CASE 
                    WHEN STATUS ILIKE '%pending%' AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5 
                      THEN 'Missing Classification - Overdue'
                    WHEN REVIEW_DUE_DATE < CURRENT_DATE() 
                      THEN 'Annual Review Overdue'
                    WHEN (REQUESTED_LABEL ILIKE '%PII%' OR REQUESTED_LABEL ILIKE '%financial%')
                         AND (CONFIDENTIALITY_LEVEL < 2 OR INTEGRITY_LEVEL < 2) 
                      THEN 'Insufficient Data Protection'
                    ELSE 'Classification Review Required'
                  END AS "Issue",
                  CASE 
                    WHEN STATUS ILIKE '%pending%' AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5 
                      THEN 'Complete asset classification within policy requirements'
                    WHEN REVIEW_DUE_DATE < CURRENT_DATE() 
                      THEN 'Complete annual security and compliance review'
                    WHEN (REQUESTED_LABEL ILIKE '%PII%' OR REQUESTED_LABEL ILIKE '%financial%')
                         AND (CONFIDENTIALITY_LEVEL < 2 OR INTEGRITY_LEVEL < 2) 
                      THEN 'Apply minimum C2+I2 protection levels'
                    ELSE 'Review and approve classification'
                  END AS "Action Plan",
                  TO_CHAR(
                    CASE 
                      WHEN STATUS ILIKE '%pending%' AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5 
                        THEN DATEADD('day', 2, CURRENT_DATE())
                      WHEN REVIEW_DUE_DATE < CURRENT_DATE() 
                        THEN DATEADD('day', 7, CURRENT_DATE())
                      WHEN (REQUESTED_LABEL ILIKE '%PII%' OR REQUESTED_LABEL ILIKE '%financial%')
                           AND (CONFIDENTIALITY_LEVEL < 2 OR INTEGRITY_LEVEL < 2) 
                        THEN DATEADD('day', 1, CURRENT_DATE())
                      ELSE DATEADD('day', 14, CURRENT_DATE())
                    END, 'YYYY-MM-DD'
                  ) AS "Due Date",
                  CASE 
                    WHEN STATUS ILIKE '%pending%' AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5 
                      THEN '40%'
                    WHEN REVIEW_DUE_DATE < CURRENT_DATE() 
                      THEN '20%'
                    WHEN (REQUESTED_LABEL ILIKE '%PII%' OR REQUESTED_LABEL ILIKE '%financial%')
                         AND (CONFIDENTIALITY_LEVEL < 2 OR INTEGRITY_LEVEL < 2) 
                      THEN '10%'
                    ELSE '60%'
                  END AS "Progress",
                  CASE 
                    WHEN STATUS ILIKE '%approved%' THEN 'Completed'
                    WHEN STATUS ILIKE '%rejected%' THEN 'Completed'
                    WHEN REVIEW_DUE_DATE < CURRENT_DATE() THEN 'Overdue'
                    WHEN STATUS ILIKE '%pending%' AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5 
                      THEN 'At Risk'
                    WHEN STATUS ILIKE '%pending%' THEN 'In Progress'
                    ELSE 'Not Started'
                  END AS "Status"
                FROM DATA_CLASSIFICATION_DB.DATA_CLASSIFICATION_GOVERNANCE.VW_CLASSIFICATION_REVIEWS
                WHERE STATUS NOT ILIKE '%approved%'
                ORDER BY 
                  CASE 
                    WHEN REVIEW_DUE_DATE < CURRENT_DATE() THEN 1
                    WHEN STATUS ILIKE '%pending%' AND DATEDIFF('day', CREATED_AT, CURRENT_DATE()) > 5 THEN 2
                    WHEN (REQUESTED_LABEL ILIKE '%PII%' OR REQUESTED_LABEL ILIKE '%financial%')
                         AND (CONFIDENTIALITY_LEVEL < 2 OR INTEGRITY_LEVEL < 2) THEN 3
                    ELSE 4
                  END,
                  CREATED_AT
                """
                
                # Execute the query
                corrective_actions = snowflake_connector.execute_query(query)
                
                if not corrective_actions:
                    st.info("No corrective actions found.")
                else:
                    # Convert to DataFrame for display
                    df = pd.DataFrame(corrective_actions)
                    
                    # Display the data in a nice table
                    st.dataframe(
                        df,
                        use_container_width=True,
                        hide_index=True
                    )
                    
                    # Add summary metrics
                    st.markdown("---")
                    
                    # Calculate metrics
                    total_actions = len(df)
                    completed = len(df[df['Status'] == 'Completed'])
                    in_progress = len(df[df['Status'] == 'In Progress'])
                    at_risk = len(df[df['Status'] == 'At Risk'])
                    overdue = len(df[df['Status'] == 'Overdue'])
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Total Actions", total_actions)
                    
                    with col2:
                        st.metric("Completed", completed)
                    
                    with col3:
                        st.metric("In Progress", in_progress)
                        
                    with col4:
                        st.metric("Requires Attention", at_risk + overdue, delta=overdue, delta_color="inverse")
                    
            except Exception as e:
                st.error(f"Error loading corrective actions: {str(e)}")
                st.warning("Using sample data as fallback")
                
                # Fallback to sample data if there's an error
                corrective_actions = pd.DataFrame({
                    'Action ID': ['CA-2024-001', 'CA-2024-002', 'CA-2024-003', 'CA-2024-004'],
                    'User': ['Sarah Chen', 'Mike Rodriguez', 'David Kim', 'Jennifer Wu'],
                    'Issue': ['Late Classification', 'Wrong Classification', 'Missing Tags', 'No Documentation'],
                    'Action Plan': ['Complete training by Dec 15', 'Reclassify 5 assets', 'Apply tags to 12 assets', 'Document 8 decisions'],
                    'Due Date': ['2024-12-15', '2024-12-10', '2024-12-08', '2024-12-20'],
                    'Progress': [60, 80, 100, 25],
                    'Status': ['In Progress', 'In Progress', 'Completed', 'At Risk']
                })
                
                st.dataframe(
                    corrective_actions,
                    use_container_width=True,
                    hide_index=True
                )

# ============================================================================
# TAB 4: REPORTS & ANALYTICS
# ============================================================================

    with tab4:
        st.header("Reports & Analytics")
        st.caption("Downloadable reports and trend analytics")
        
        # Report generation
        st.markdown("### Generate Compliance Reports")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**Executive Summary**")
            if st.button("ðŸ“Š Generate Executive Report", use_container_width=True):
                with st.spinner("Generating executive summary..."):
                    # Fetch summarized metrics
                    metrics = get_classification_requirements_metrics(db)
                    
                    summary_data = {
                        'Metric': [
                            'Classification Coverage', 
                            '5-Day Rule Compliance', 
                            'Annual Review Completion', 
                            'Documentation Completeness',
                            'Policy Violations'
                        ],
                        'Value': [
                            f"{metrics.get('coverage', 0):.1f}%",
                            f"{metrics.get('five_day_compliance', 0):.1f}%",
                            f"{metrics.get('annual_review', 0):.1f}%",
                            f"{metrics.get('doc_completeness', 0):.1f}%",
                            f"{metrics.get('policy_violations', 0)}"
                        ],
                        'Status': [
                            metrics.get('overall_status', 'Unknown'),
                            'Healthy' if metrics.get('five_day_compliance', 0) >= 95 else 'Warning',
                            'Healthy' if metrics.get('annual_review', 0) >= 80 else 'Warning',
                            'Healthy' if metrics.get('doc_completeness', 0) >= 95 else 'Warning',
                            'Action Required' if metrics.get('policy_violations', 0) > 0 else 'Healthy'
                        ]
                    }
                    exec_df = pd.DataFrame(summary_data)
                    csv = exec_df.to_csv(index=False).encode('utf-8')
                    
                    st.success("Executive summary generated!")
                    st.download_button(
                        label="ðŸ“¥ Download Summary CSV",
                        data=csv,
                        file_name=f"executive_summary_{datetime.now().strftime('%Y%m%d')}.csv",
                        mime="text/csv",
                        key='download_exec'
                    )
        
        with col2:
            st.markdown("**Detailed Compliance**")
            if st.button("ðŸ“‹ Generate Detailed Report", use_container_width=True):
                with st.spinner("Fetching full asset inventory..."):
                    try:
                        # Full asset dump
                        query = f"SELECT * FROM {db}.{_gv_schema()}.ASSETS LIMIT 10000"
                        detailed_df = snowflake_connector.execute_query(query)
                        
                        if detailed_df:
                            df = pd.DataFrame(detailed_df)
                            csv = df.to_csv(index=False).encode('utf-8')
                            
                            st.success(f"Report generated for {len(df)} assets!")
                            st.download_button(
                                label="ðŸ“¥ Download Detailed CSV",
                                data=csv,
                                file_name=f"detailed_compliance_{datetime.now().strftime('%Y%m%d')}.csv",
                                mime="text/csv",
                                key='download_detailed'
                            )
                        else:
                            st.warning("No data found in generic asset view.")
                    except Exception as e:
                        st.error(f"Error generating report: {e}")
        
        with col3:
            st.markdown("**Audit Package**")
            if st.button("ðŸ“¦ Generate Audit Package", use_container_width=True):
                 with st.spinner("Compiling audit evidence..."):
                    # Use policy violations as the core evidence log
                    violations_log = get_policy_violations(db)
                    
                    if violations_log is not None and not violations_log.empty:
                        csv = violations_log.to_csv(index=False).encode('utf-8')
                        
                        st.success("Audit package compiled!")
                        st.download_button(
                            label="ðŸ“¥ Download Audit Evidence Logs",
                            data=csv,
                            file_name=f"audit_pack_evidence_{datetime.now().strftime('%Y%m%d')}.csv",
                            mime="text/csv",
                            key='download_audit'
                        )
                    else:
                        st.warning("No violations or audit evidence found to package.")
    
        st.markdown("---")
        
        # Trend analytics
        st.markdown("### Trend Analytics")
        
        with st.spinner("Calculating compliance trends..."):
            trend_df = get_compliance_trends_metrics(db)
        
        if not trend_df.empty:
            # Normalize column names to upper case
            trend_df.columns = [c.upper() for c in trend_df.columns]
            
            # Ensure month is sorted ascending for charts
            chart_df = trend_df.sort_values('MONTH_PERIOD')
            
            # Line chart for Overall Trends
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=chart_df['MONTH_PERIOD'],
                y=chart_df['OVERALL_COMPLIANCE_SCORE'],
                name='Overall Compliance Score',
                mode='lines+markers',
                line=dict(color='#2C3E50', width=4),
                hovertemplate='%{y:.1f}%'
            ))
            
            fig.add_trace(go.Scatter(
                x=chart_df['MONTH_PERIOD'],
                y=chart_df['POLICY_COMPLIANCE_PCT'],
                name='Policy Compliance',
                mode='lines+markers',
                line=dict(color='#27AE60', width=2, dash='dot')
            ))
            
            fig.add_trace(go.Scatter(
                x=chart_df['MONTH_PERIOD'],
                y=chart_df['GOVERNANCE_COMPLETION_PCT'],
                name='Governance Completion',
                mode='lines+markers',
                line=dict(color='#2980B9', width=2, dash='dot')
            ))
            
            fig.add_trace(go.Scatter(
                x=chart_df['MONTH_PERIOD'],
                y=chart_df['AUDIT_COMPLIANCE_PCT'],
                name='Audit Status',
                mode='lines+markers',
                line=dict(color='#F1C40F', width=2, dash='dot')
            ))
            
            fig.add_trace(go.Scatter(
                x=chart_df['MONTH_PERIOD'],
                y=chart_df['RISK_COMPLIANCE_PCT'],
                name='Risk Score',
                mode='lines+markers',
                line=dict(color='#E74C3C', width=2, dash='dot')
            ))
            
            fig.update_layout(
                title="Compliance Trends (Last 6 Months)",
                xaxis_title="Month",
                yaxis_title="Score / Percentage",
                hovermode='x unified',
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1
                )
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Detailed Trend Table
            st.write("#### Detailed Trend Analysis")
            
            # Select and rename columns for meaningful display
            display_cols = [
                'MONTH_PERIOD',
                'OVERALL_COMPLIANCE_SCORE', 'OVERALL_TREND',
                'POLICY_COMPLIANCE_PCT', 'POLICY_TREND',
                'GOVERNANCE_COMPLETION_PCT', 'GOVERNANCE_TREND',
                'AUDIT_COMPLIANCE_PCT', 'AUDIT_TREND',
                'RISK_COMPLIANCE_PCT', 'RISK_TREND'
            ]
            
            # Check if columns exist (safety check)
            available_cols = [c for c in display_cols if c in trend_df.columns]
            
            display_df = trend_df[available_cols].copy()
            
            # Rename for display
            display_df.rename(columns={
                'MONTH_PERIOD': 'Month',
                'OVERALL_COMPLIANCE_SCORE': 'Overall Score',
                'OVERALL_TREND': 'Trend',
                'POLICY_COMPLIANCE_PCT': 'Policy %',
                'POLICY_TREND': 'Trend ',
                'GOVERNANCE_COMPLETION_PCT': 'Governance %',
                'GOVERNANCE_TREND': 'Trend  ',
                'AUDIT_COMPLIANCE_PCT': 'Audit %',
                'AUDIT_TREND': 'Trend   ',
                'RISK_COMPLIANCE_PCT': 'Risk Score',
                'RISK_TREND': 'Trend    '
            }, inplace=True)
            
            st.dataframe(
                display_df, 
                use_container_width=True, 
                hide_index=True
            )
            
        else:
            st.warning("No trend data available for the last 6 months.")
        
        st.markdown("---")
        
        # Export options
        st.markdown("### Export Data")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ðŸ“¥ Export as CSV", use_container_width=True):
                csv = trend_df.to_csv(index=False)
                st.download_button(
                    label="Download CSV",
                    data=csv,
                    file_name=f"compliance_trends_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
        
        with col2:
            if st.button("ðŸ“¥ Export as Excel", use_container_width=True):
                st.info("Excel export functionality would be implemented here")
        
        with col3:
            if st.button("ðŸ“¥ Export as PDF", use_container_width=True):
                st.info("PDF export functionality would be implemented here")

# ============================================================================
# FOOTER
# ============================================================================

st.markdown("---")
st.caption(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Policy: AVD-DWH-DCLS-001")
